{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/horse/ws/jori152b-medinf/KP_MedInf\n",
      "/data/horse/ws/jori152b-medinf/KP_MedInf/notebooks\n"
     ]
    }
   ],
   "source": [
    "# only for taurus\n",
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir(\"notebooks\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-20 12:59:52.899070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/horse/ws/jori152b-medinf/KP_MedInf/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())\n",
    "#data preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "# NN\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import math\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, f1_score, roc_auc_score, auc, accuracy_score\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from captum.attr import IntegratedGradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if (torch.cuda.is_available()):\n",
    "    print('Training on GPU')\n",
    "else:\n",
    "    print('Training on CPU') # On mac book GPU is not possible =() \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter as constant \n",
    "\n",
    "TESTING = False \n",
    "TEST_SIZE = 0.05\n",
    "\n",
    "SPLIT_SIZE = 0.2 \n",
    "\n",
    "NORMALIZATION = 'min-max' \n",
    "\n",
    "CAPPING_THRESHOLD_UPPER = 0.99\n",
    "CAPPING_THRESHOLD_LOWER = 0.01\n",
    "\n",
    "# How much time the prediction should occur (hours)\n",
    "HOURS_AHEAD = 48\n",
    "\n",
    "NORM_TYPE = 'min_max'\n",
    "\n",
    "RANDOM = 42\n",
    "\n",
    "# LSTM\n",
    "batch_size = 5\n",
    "\n",
    "# naming model and plot\n",
    "classifier_name = \"None vs. Any AKI\"    ###change every time #Moderate vs. Severe #None vs. Any #Others vs. Severe\n",
    "plot_name = \"adult_AnyAKI_LR\"    ###change every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions used later\n",
    "\n",
    "def cap_data(df):\n",
    "    print(\"Capping between the {} and {} quantile\".format(CAPPING_THRESHOLD_LOWER, CAPPING_THRESHOLD_UPPER))\n",
    "    cap_mask = df.columns.difference(['icustay_id', 'charttime', 'aki_stage'])\n",
    "    df[cap_mask] = df[cap_mask].clip(df[cap_mask].quantile(CAPPING_THRESHOLD_LOWER),\n",
    "                                     df[cap_mask].quantile(CAPPING_THRESHOLD_UPPER),\n",
    "                                     axis=1)\n",
    "\n",
    "    return df\n",
    " \n",
    "    \n",
    "def normalise_data(df, norm_mask):\n",
    "    print(\"Normalizing in [0,1] with {} normalization\".format(NORMALIZATION))\n",
    "    \n",
    "    min_values = df[norm_mask].min()\n",
    "    max_values = df[norm_mask].max()\n",
    "    \n",
    "    # Skip normalization for constant columns\n",
    "    for column in norm_mask:\n",
    "        if min_values[column] != max_values[column]:\n",
    "            df[column] = (df[column] - min_values[column]) / (max_values[column] - min_values[column])\n",
    "    \n",
    "    normalization_parameters = {column: {'min': min_values[column], 'max': max_values[column]} for column in norm_mask}\n",
    "    \n",
    "    return df, normalization_parameters\n",
    "\n",
    "\n",
    "# impute missing value in resampleing data with most common based on each id\n",
    "def fast_mode(df, key_cols, value_col):\n",
    "    \"\"\" Calculate a column mode, by group, ignoring null values. \n",
    "    \n",
    "    key_cols : list of str - Columns to groupby for calculation of mode.\n",
    "    value_col : str - Column for which to calculate the mode. \n",
    "\n",
    "    Return\n",
    "    pandas.DataFrame\n",
    "        One row for the mode of value_col per key_cols group. If ties, returns the one which is sorted first. \"\"\"\n",
    "    return (df.groupby(key_cols + [value_col]).size() \n",
    "              .to_frame('counts').reset_index() \n",
    "              .sort_values('counts', ascending=False) \n",
    "              .drop_duplicates(subset=key_cols)).drop('counts',axis=1)\n",
    "\n",
    "\n",
    "#get max shape of 3d array\n",
    "def get_dimensions(array, level=0):   \n",
    "    yield level, len(array)\n",
    "    try:\n",
    "        for row in array:\n",
    "            yield from get_dimensions(row, level + 1)\n",
    "    except TypeError: #not an iterable\n",
    "        pass\n",
    "\n",
    "def get_max_shape(array):\n",
    "    dimensions = defaultdict(int)\n",
    "    for level, length in get_dimensions(array):\n",
    "        dimensions[level] = max(dimensions[level], length)\n",
    "    return [value for _, value in sorted(dimensions.items())]\n",
    "\n",
    "#pad the ragged 3d array to rectangular shape based on max size\n",
    "def iterate_nested_array(array, index=()):\n",
    "    try:\n",
    "        for idx, row in enumerate(array):\n",
    "            yield from iterate_nested_array(row, (*index, idx)) \n",
    "    except TypeError: # final level            \n",
    "        yield (*index, slice(len(array))), array # think of the types\n",
    "\n",
    "def pad(array, fill_value):\n",
    "    dimensions = get_max_shape(array)\n",
    "    result = np.full(dimensions, fill_value, dtype = np.float64)  \n",
    "    for index, value in iterate_nested_array(array):\n",
    "        result[index] = value \n",
    "    return result\n",
    "\n",
    "def bin_total(y_true, y_prob, n_bins):\n",
    "    bins = np.linspace(0., 1. + 1e-8, n_bins + 1)\n",
    "\n",
    "    # In sklearn.calibration.calibration_curve,\n",
    "    # the last value in the array is always 0.\n",
    "    binids = np.digitize(y_prob, bins) - 1\n",
    "\n",
    "    return np.bincount(binids, minlength=len(bins))\n",
    "\n",
    "def missing_bin(bin_array):\n",
    "    midpoint = \" \"    \n",
    "    if bin_array[0]==0:\n",
    "        midpoint = \"5%, \"\n",
    "    if bin_array[1]==0:\n",
    "        midpoint = midpoint + \"15%, \"\n",
    "    if bin_array[2]==0:\n",
    "        midpoint = midpoint + \"25%, \"\n",
    "    if bin_array[3]==0:\n",
    "        midpoint = midpoint + \"35%, \" \n",
    "    if bin_array[4]==0:\n",
    "        midpoint = midpoint + \"45%, \"\n",
    "    if bin_array[5]==0:\n",
    "        midpoint = midpoint + \"55%, \"\n",
    "    if bin_array[6]==0:\n",
    "        midpoint = midpoint + \"65%, \"\n",
    "    if bin_array[7]==0:\n",
    "        midpoint = midpoint + \"75%, \"\n",
    "    if bin_array[8]==0:\n",
    "        midpoint = midpoint + \"85%, \"\n",
    "    if bin_array[9]==0:\n",
    "        midpoint = midpoint + \"95%, \"\n",
    "    return \"The missing bins have midpoint values of \"+ str(midpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing in [0,1] with min-max normalization\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 36\u001b[0m\n\u001b[1;32m     31\u001b[0m numeric_feat\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124micustay_id\u001b[39m\u001b[38;5;124m'\u001b[39m,)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# normalize data and cap features\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# X = cap_data(X)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m X, normalization_parameters \u001b[38;5;241m=\u001b[39m \u001b[43mnormalise_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_feat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# X = X.sort_values(by=['icustay_id', 'charttime'])\u001b[39;00m\n\u001b[1;32m     39\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124micustay_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m, in \u001b[0;36mnormalise_data\u001b[0;34m(df, norm_mask)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNormalizing in [0,1] with \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m normalization\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(NORMALIZATION))\n\u001b[1;32m     16\u001b[0m min_values \u001b[38;5;241m=\u001b[39m df[norm_mask]\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m---> 17\u001b[0m max_values \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnorm_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmax()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Skip normalization for constant columns\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m norm_mask:\n",
      "File \u001b[0;32m/data/horse/ws/jori152b-medinf/KP_MedInf/venv/lib/python3.10/site-packages/pandas/core/frame.py:4117\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   4115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice(indexer, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 4117\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[1;32m   4120\u001b[0m     \u001b[38;5;66;03m# What does looking for a single key in a non-unique index return?\u001b[39;00m\n\u001b[1;32m   4121\u001b[0m     \u001b[38;5;66;03m# The behavior is inconsistent. It returns a Series, except when\u001b[39;00m\n\u001b[1;32m   4122\u001b[0m     \u001b[38;5;66;03m# - the key itself is repeated (test on data.shape, #9519), or\u001b[39;00m\n\u001b[1;32m   4123\u001b[0m     \u001b[38;5;66;03m# - we have a MultiIndex on columns (test on self.columns, #21309)\u001b[39;00m\n\u001b[1;32m   4124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n\u001b[1;32m   4125\u001b[0m         \u001b[38;5;66;03m# GH#26490 using data[key] can cause RecursionError\u001b[39;00m\n",
      "File \u001b[0;32m/data/horse/ws/jori152b-medinf/KP_MedInf/venv/lib/python3.10/site-packages/pandas/core/generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   4143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   4144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4145\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   4146\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4151\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4154\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   4155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m/data/horse/ws/jori152b-medinf/KP_MedInf/venv/lib/python3.10/site-packages/pandas/core/generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4128\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[1;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4131\u001b[0m     )\n\u001b[0;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4140\u001b[0m )\n",
      "File \u001b[0;32m/data/horse/ws/jori152b-medinf/KP_MedInf/venv/lib/python3.10/site-packages/pandas/core/internals/managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[1;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/horse/ws/jori152b-medinf/KP_MedInf/venv/lib/python3.10/site-packages/pandas/core/internals/managers.py:680\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice_take_blocks_ax0\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_proxy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[1;32m    689\u001b[0m             indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    696\u001b[0m     ]\n",
      "File \u001b[0;32m/data/horse/ws/jori152b-medinf/KP_MedInf/venv/lib/python3.10/site-packages/pandas/core/internals/managers.py:843\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy, ref_inplace_op)\u001b[0m\n\u001b[1;32m    841\u001b[0m                     blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[1;32m    842\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 843\u001b[0m                 nb \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_mgr_locs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmgr_locs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m                 blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m blocks\n",
      "File \u001b[0;32m/data/horse/ws/jori152b-medinf/KP_MedInf/venv/lib/python3.10/site-packages/pandas/core/internals/blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[0;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[0;32m/data/horse/ws/jori152b-medinf/KP_MedInf/venv/lib/python3.10/site-packages/pandas/core/array_algos/take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[1;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/horse/ws/jori152b-medinf/KP_MedInf/venv/lib/python3.10/site-packages/pandas/core/array_algos/take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[1;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[1;32m    161\u001b[0m )\n\u001b[0;32m--> 162\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[1;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import os\n",
    "import gc\n",
    "\n",
    "results = {}\n",
    "\n",
    "\n",
    "data_paths = [\"../data/preprocessed/preprocessed_data_extended_1H.csv\",\n",
    "              \"../data/preprocessed/preprocessed_data_extended_2H.csv\",\n",
    "              \"../data/preprocessed/preprocessed_data_extended_3H.csv\",\n",
    "              \"../data/preprocessed/preprocessed_data_extended_4H.csv\",\n",
    "              \"../data/preprocessed/preprocessed_data_extended_5H.csv\",\n",
    "              \"../data/preprocessed/preprocessed_data_extended_6H.csv\",\n",
    "              \"../data/preprocessed/preprocessed_data.csv\",]\n",
    "\n",
    "for data_path in data_paths:\n",
    "    \n",
    "    tail = data_path.split(\"/\")[-1]\n",
    "    X = pd.read_csv(data_path)\n",
    "    # take only head \n",
    "    # X = X.head(10000)\n",
    "\n",
    "    # For training a testing model, take only icu_stay_id, charttime,creatinine_mean,uo_rt_6hr,aki_stage\n",
    "    # X = X[['icustay_id', 'charttime', 'creatinine_mean', 'uo_rt_6hr', 'aki_stage']]\n",
    "\n",
    "    numeric_feat = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    numeric_feat.remove('aki_stage',)\n",
    "    numeric_feat.remove('icustay_id',)\n",
    "\n",
    "\n",
    "    # normalize data and cap features\n",
    "    # X = cap_data(X)\n",
    "    X, normalization_parameters = normalise_data(X, numeric_feat)\n",
    "\n",
    "    # X = X.sort_values(by=['icustay_id', 'charttime'])\n",
    "    X = X.sort_values(by=['icustay_id'])\n",
    "\n",
    "    seq_lengths = X.groupby(['icustay_id'],as_index=False).size().sort_values(by = ['size'],ascending=False)\n",
    "    sequence_length = seq_lengths.max() # the longest sequence per icustay-id\n",
    "    print(sequence_length)\n",
    "\n",
    "    #AL re-write as try except to make it work as hadm_id is not used if only one csv file is used and none are merged\n",
    "    try:\n",
    "        X.drop(['hadm_id'], axis=1, inplace = True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    id_list = X['icustay_id'].unique()\n",
    "    id_train, id_test_val = train_test_split(id_list, test_size = SPLIT_SIZE, random_state = 42) # train set is 80%)\n",
    "    print(\"train is %d\" % len(id_train))\n",
    "    # remaining 20% split in halves as test and validation 10% and 10%\n",
    "    id_valid, id_test = train_test_split(id_test_val, test_size = 0.5, random_state = 42) # test 10% valid 10%\n",
    "    print(\"val and test are %d\" %len(id_test))\n",
    "\n",
    "    # move (\"aki_stage\") to last column\n",
    "    X = X.reindex(columns = [col for col in X.columns if col != 'aki_stage'] + ['aki_stage'])\n",
    "\n",
    "    train = X[X.icustay_id.isin(id_train)].sort_values(by=['icustay_id'])\n",
    "    test = X[X.icustay_id.isin(id_test)].sort_values(by=['icustay_id'], ignore_index = True) \n",
    "    validation = X[X.icustay_id.isin(id_valid)].sort_values(by=['icustay_id']) \n",
    "\n",
    "    test = test.sort_values(by=['icustay_id'], ignore_index = True)\n",
    "    train = train.sort_values(by=['icustay_id'], ignore_index = True)\n",
    "    validation = validation.sort_values(by=['icustay_id'], ignore_index = True)\n",
    "\n",
    "    train.drop(['charttime'], axis=1, inplace = True)  \n",
    "    test.drop(['charttime'], axis=1, inplace = True)\n",
    "    validation.drop(['charttime'], axis=1, inplace = True)\n",
    "\n",
    "    try:\n",
    "        X.drop(['hadm_id'], axis=1, inplace = True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    train = train.groupby(['icustay_id'],as_index=False).apply(pd.DataFrame.to_numpy)\n",
    "    test = test.groupby(['icustay_id'],as_index=False).apply(pd.DataFrame.to_numpy)\n",
    "    validation = validation.groupby(['icustay_id'],as_index=False).apply(pd.DataFrame.to_numpy)\n",
    "\n",
    "\n",
    "    # flatten the train, test and validation data\n",
    "    train_flat = np.concatenate(train, axis=0)\n",
    "    test_flat = np.concatenate(test, axis=0)\n",
    "    validation_flat = np.concatenate(validation, axis=0)\n",
    "\n",
    "    # get the labels\n",
    "    train_labels = np.array([x[-1] for x in train_flat])\n",
    "    test_labels = np.array([x[-1] for x in test_flat])\n",
    "    validation_labels = np.array([x[-1] for x in validation_flat])\n",
    "\n",
    "    # get the features\n",
    "    train_features = np.array([x[1:-1] for x in train_flat])\n",
    "\n",
    "    # create the XGBoost classifier\n",
    "    xgb = XGBClassifier(n_estimators=1000, use_label_encoder=False, eval_metric='mlogloss', random_state=RANDOM)\n",
    "\n",
    "    # train the classifier\n",
    "    xgb.fit(train_features, train_labels)\n",
    "\n",
    "    # get the predictions\n",
    "    train_predictions = xgb.predict(np.array([x[1:-1] for x in train_flat]))\n",
    "    test_predictions = xgb.predict(np.array([x[1:-1] for x in test_flat]))\n",
    "    validation_predictions = xgb.predict(np.array([x[1:-1] for x in validation_flat]))\n",
    "\n",
    "    # get the accuracy\n",
    "    train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "    test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "    validation_accuracy = accuracy_score(validation_labels, validation_predictions)\n",
    "\n",
    "    print(f'Train accuracy: {train_accuracy}')\n",
    "    print(f'Test accuracy: {test_accuracy}')\n",
    "    print(f'Validation accuracy: {validation_accuracy}')\n",
    "\n",
    "\n",
    "    # get the probabilities of the positive class\n",
    "    training_prob = xgb.predict_proba([x[1:-1] for x in train_flat])[:, 1]\n",
    "    test_prob = xgb.predict_proba([x[1:-1] for x in test_flat])[:, 1]\n",
    "    validation_prob = xgb.predict_proba([x[1:-1] for x in validation_flat])[:, 1]\n",
    "\n",
    "    # calculate ROC AUC and PR AUC for the training set\n",
    "    training_roc_auc = roc_auc_score(train_labels, training_prob)\n",
    "    training_pr_auc = average_precision_score(train_labels, training_prob)\n",
    "\n",
    "    # calculate ROC AUC and PR AUC for the test set\n",
    "    test_roc_auc = roc_auc_score(test_labels, test_prob)\n",
    "    test_pr_auc = average_precision_score(test_labels, test_prob)\n",
    "\n",
    "    # calculate ROC AUC and PR AUC for the validation set\n",
    "    validation_roc_auc = roc_auc_score(validation_labels, validation_prob)\n",
    "    validation_pr_auc = average_precision_score(validation_labels, validation_prob)\n",
    "\n",
    "    print(f\"Train accuracy: {train_accuracy:.3f}.. Train ROC AUC: {training_roc_auc:.2f}.. Train PR AUC: {training_pr_auc:.2f}..\")\n",
    "    print(f\"Test accuracy: {test_accuracy:.3f}.. Test ROC AUC: {test_roc_auc:.2f}.. Test PR AUC: {test_pr_auc:.2f}..\")\n",
    "    print(f\"Validation accuracy: {validation_accuracy:.3f}.. Validation ROC AUC: {validation_roc_auc:.2f}.. Validation PR AUC: {validation_pr_auc:.2f}..\")\n",
    "\n",
    "    now = datetime.now()\n",
    "    out_path = f'data/models/{tail}'\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    # save the xgb model\n",
    "    xgb.save_model(f'{out_path}/xgb.model')\n",
    "    # save normalization parameters\n",
    "    try:\n",
    "        np.save(f'{out_path}/normalization_parameters.npy', normalization_parameters)\n",
    "    except:\n",
    "        pass\n",
    "    # save the train feature names\n",
    "    np.save(f'{out_path}/train_feature_names.npy', X.columns[2:-1])\n",
    "\n",
    "    results[tail] = {'train_accuracy': train_accuracy, 'test_accuracy': test_accuracy, 'validation_accuracy': validation_accuracy,\n",
    "                                'train_roc_auc': training_roc_auc, 'test_roc_auc': test_roc_auc, 'validation_roc_auc': validation_roc_auc,\n",
    "                                'train_pr_auc': training_pr_auc, 'test_pr_auc': test_pr_auc, 'validation_pr_auc': validation_pr_auc}\n",
    "\n",
    "    # save results dict\n",
    "    np.save(f'data/results.npy', results)\n",
    "    \n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing in [0,1] with min-max normalization\n",
      "icustay_id    299999\n",
      "size             793\n",
      "dtype: int64\n",
      "train is 37801\n",
      "val and test are 4726\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "\n",
    "SAMPLING_INTERVALS = [\"1H\"]\n",
    "\n",
    "for SAMPLING_INTERVAL in SAMPLING_INTERVALS:\n",
    "    X = pd.read_csv(f'../data/preprocessed/preprocessed_data_extended_{SAMPLING_INTERVAL}.csv')\n",
    "    # take only head \n",
    "    # X = X.head(10000)\n",
    "\n",
    "    # For training a testing model, take only icu_stay_id, charttime,creatinine_mean,uo_rt_6hr,aki_stage\n",
    "    # X = X[['icustay_id', 'charttime', 'creatinine_mean', 'uo_rt_6hr', 'aki_stage']]\n",
    "\n",
    "    numeric_feat = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    numeric_feat.remove('aki_stage',)\n",
    "    numeric_feat.remove('icustay_id',)\n",
    "\n",
    "\n",
    "    # normalize data and cap features\n",
    "    # X = cap_data(X)\n",
    "    X, normalization_parameters = normalise_data(X, numeric_feat)\n",
    "\n",
    "    # X = X.sort_values(by=['icustay_id', 'charttime'])\n",
    "    X = X.sort_values(by=['icustay_id'])\n",
    "\n",
    "    seq_lengths = X.groupby(['icustay_id'],as_index=False).size().sort_values(by = ['size'],ascending=False)\n",
    "    sequence_length = seq_lengths.max() # the longest sequence per icustay-id\n",
    "    print(sequence_length)\n",
    "\n",
    "    #AL re-write as try except to make it work as hadm_id is not used if only one csv file is used and none are merged\n",
    "    try:\n",
    "        X.drop(['hadm_id'], axis=1, inplace = True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    id_list = X['icustay_id'].unique()\n",
    "    id_train, id_test_val = train_test_split(id_list, test_size = SPLIT_SIZE, random_state = 42) # train set is 80%)\n",
    "    print(\"train is %d\" % len(id_train))\n",
    "    # remaining 20% split in halves as test and validation 10% and 10%\n",
    "    id_valid, id_test = train_test_split(id_test_val, test_size = 0.5, random_state = 42) # test 10% valid 10%\n",
    "    print(\"val and test are %d\" %len(id_test))\n",
    "\n",
    "    # move (\"aki_stage\") to last column\n",
    "    X = X.reindex(columns = [col for col in X.columns if col != 'aki_stage'] + ['aki_stage'])\n",
    "\n",
    "    train = X[X.icustay_id.isin(id_train)].sort_values(by=['icustay_id'])\n",
    "    test = X[X.icustay_id.isin(id_test)].sort_values(by=['icustay_id'], ignore_index = True) \n",
    "    validation = X[X.icustay_id.isin(id_valid)].sort_values(by=['icustay_id']) \n",
    "\n",
    "    test = test.sort_values(by=['icustay_id'], ignore_index = True)\n",
    "    train = train.sort_values(by=['icustay_id'], ignore_index = True)\n",
    "    validation = validation.sort_values(by=['icustay_id'], ignore_index = True)\n",
    "\n",
    "    train.drop(['charttime'], axis=1, inplace = True)  \n",
    "    test.drop(['charttime'], axis=1, inplace = True)\n",
    "    validation.drop(['charttime'], axis=1, inplace = True)\n",
    "\n",
    "    try:\n",
    "        X.drop(['hadm_id'], axis=1, inplace = True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    train = train.groupby(['icustay_id'],as_index=False).apply(pd.DataFrame.to_numpy)\n",
    "    test = test.groupby(['icustay_id'],as_index=False).apply(pd.DataFrame.to_numpy)\n",
    "    validation = validation.groupby(['icustay_id'],as_index=False).apply(pd.DataFrame.to_numpy)\n",
    "\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "    # flatten the train, test and validation data\n",
    "    train_flat = np.concatenate(train, axis=0)\n",
    "    test_flat = np.concatenate(test, axis=0)\n",
    "    validation_flat = np.concatenate(validation, axis=0)\n",
    "\n",
    "    # get the labels\n",
    "    train_labels = np.array([x[-1] for x in train_flat])\n",
    "    test_labels = np.array([x[-1] for x in test_flat])\n",
    "    validation_labels = np.array([x[-1] for x in validation_flat])\n",
    "\n",
    "    # get the features\n",
    "    train_features = np.array([x[1:-1] for x in train_flat])\n",
    "\n",
    "    # create the XGBoost classifier\n",
    "    xgb = XGBClassifier(n_estimators=1000, use_label_encoder=False, eval_metric='mlogloss', random_state=RANDOM)\n",
    "\n",
    "    # train the classifier\n",
    "    xgb.fit(train_features, train_labels)\n",
    "\n",
    "    # get the predictions\n",
    "    train_predictions = xgb.predict(np.array([x[1:-1] for x in train_flat]))\n",
    "    test_predictions = xgb.predict(np.array([x[1:-1] for x in test_flat]))\n",
    "    validation_predictions = xgb.predict(np.array([x[1:-1] for x in validation_flat]))\n",
    "\n",
    "    # get the accuracy\n",
    "    train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "    test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "    validation_accuracy = accuracy_score(validation_labels, validation_predictions)\n",
    "\n",
    "    print(f'Train accuracy: {train_accuracy}')\n",
    "    print(f'Test accuracy: {test_accuracy}')\n",
    "    print(f'Validation accuracy: {validation_accuracy}')\n",
    "\n",
    "    from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "    # get the probabilities of the positive class\n",
    "    training_prob = xgb.predict_proba([x[1:-1] for x in train_flat])[:, 1]\n",
    "    test_prob = xgb.predict_proba([x[1:-1] for x in test_flat])[:, 1]\n",
    "    validation_prob = xgb.predict_proba([x[1:-1] for x in validation_flat])[:, 1]\n",
    "\n",
    "    # calculate ROC AUC and PR AUC for the training set\n",
    "    training_roc_auc = roc_auc_score(train_labels, training_prob)\n",
    "    training_pr_auc = average_precision_score(train_labels, training_prob)\n",
    "\n",
    "    # calculate ROC AUC and PR AUC for the test set\n",
    "    test_roc_auc = roc_auc_score(test_labels, test_prob)\n",
    "    test_pr_auc = average_precision_score(test_labels, test_prob)\n",
    "\n",
    "    # calculate ROC AUC and PR AUC for the validation set\n",
    "    validation_roc_auc = roc_auc_score(validation_labels, validation_prob)\n",
    "    validation_pr_auc = average_precision_score(validation_labels, validation_prob)\n",
    "\n",
    "    print(f\"Train accuracy: {train_accuracy:.3f}.. Train ROC AUC: {training_roc_auc:.2f}.. Train PR AUC: {training_pr_auc:.2f}..\")\n",
    "    print(f\"Test accuracy: {test_accuracy:.3f}.. Test ROC AUC: {test_roc_auc:.2f}.. Test PR AUC: {test_pr_auc:.2f}..\")\n",
    "    print(f\"Validation accuracy: {validation_accuracy:.3f}.. Validation ROC AUC: {validation_roc_auc:.2f}.. Validation PR AUC: {validation_pr_auc:.2f}..\")\n",
    "\n",
    "    import os\n",
    "    now = datetime.now()\n",
    "    out_path = f'data/models/{SAMPLING_INTERVAL}'\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    # save the xgb model\n",
    "    xgb.save_model(f'{out_path}/xgb.model')\n",
    "    # save normalization parameters\n",
    "    try:\n",
    "        np.save(f'{out_path}/normalization_parameters.npy', normalization_parameters)\n",
    "    except:\n",
    "        pass\n",
    "    # save the train feature names\n",
    "    np.save(f'{out_path}/train_feature_names.npy', X.columns[2:-1])\n",
    "\n",
    "    results[SAMPLING_INTERVAL] = {'train_accuracy': train_accuracy, 'test_accuracy': test_accuracy, 'validation_accuracy': validation_accuracy,\n",
    "                                'train_roc_auc': training_roc_auc, 'test_roc_auc': test_roc_auc, 'validation_roc_auc': validation_roc_auc,\n",
    "                                'train_pr_auc': training_pr_auc, 'test_pr_auc': test_pr_auc, 'validation_pr_auc': validation_pr_auc}\n",
    "    \n",
    "# save results dict\n",
    "np.save(f'data/results.npy', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model and predict    \n",
    "loaded_model = XGBClassifier()\n",
    "loaded_model.load_model('data/models/simple_xgboost_model.model')\n",
    "test_predictions = loaded_model.predict(np.array([x[1:-1] for x in test_flat]))\n",
    "validation_predictions = loaded_model.predict(np.array([x[1:-1] for x in validation_flat]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (torch.cuda.is_available()):\n",
    "    print('Training on GPU')\n",
    "else:\n",
    "    print('Training on CPU') # On mac book GPU is not possible =() \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(np.array(train)).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def batch(data, batch_size):\n",
    "    X_batches = []\n",
    "    y_batches = []\n",
    "    times = math.floor(data.shape[0]/batch_size)\n",
    "    remainder = data.shape[0]%times\n",
    "    a = 0\n",
    "    start = 0\n",
    "    end = start+batch_size\n",
    "    if remainder ==0:\n",
    "        a +=1\n",
    "    while a<times:\n",
    "        temp = pad(data[start:end,],0)\n",
    "        x = torch.from_numpy(temp[:,:,1:-1]).float() # without icustay_id and without aki_stage columns\n",
    "        y = torch.flatten(torch.from_numpy(temp[:, :,-1].reshape(-1,1)).float()).long()\n",
    "        X_batches.append(x)\n",
    "        y_batches.append(y)\n",
    "        start = end\n",
    "        end = start+batch_size\n",
    "        a +=1\n",
    "    temp = pad(data[start:data.shape[0]],0)\n",
    "    x = torch.from_numpy(temp[:,:,1:-1]).float()\n",
    "    y = torch.flatten(torch.from_numpy(temp[:, :,-1].reshape(-1,1)).float()).long()\n",
    "    X_batches.append(x)\n",
    "    y_batches.append(y)\n",
    "    if len(X_batches) != len(y_batches):\n",
    "        print(\"length error\")\n",
    "    return X_batches, y_batches # arrays\n",
    "\n",
    "# batching\n",
    "X_train, y_train = batch(train, batch_size) # to count weights\n",
    "\n",
    "# counting balance of the classes\n",
    "y = []\n",
    "for i in y_train:\n",
    "    for element in i:\n",
    "        y.append(element.item())\n",
    "\n",
    "#  weights\n",
    "counter=collections.Counter(y)\n",
    "print(counter)\n",
    "zeroes = counter[0]\n",
    "ones = counter[1]\n",
    "\n",
    "X_test, y_test = batch(test, test.shape[0]) \n",
    "X_val, y_val = batch(validation, validation.shape[0])\n",
    "X_val = X_val[0]\n",
    "y_val = y_val[0]\n",
    "X_test = X_test[0]\n",
    "y_test = y_test[0]\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_val[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# setup\n",
    "\n",
    "bi_directional = True\n",
    "n_epochs = 50\n",
    "lr = 0.001\n",
    "features = len(X_train[0][0][0])\n",
    "print(features)\n",
    "# features = \n",
    "emb_size = round(features/1)\n",
    "number_layers = 3\n",
    "dropout = 0 # dropout\n",
    "\n",
    "##########################\n",
    "input_size = features\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, output_size, bi_directional, number_layers, dropout):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.emb_size = emb_size \n",
    "        self.output_size = output_size\n",
    "        self.number_layers = number_layers\n",
    "        self.fc1 = nn.Linear(self.input_size, self.emb_size, bias = True) # I can have a few (IV) within this line - documentation        \n",
    "        self.fc2 = nn.LSTM(self.emb_size, self.output_size,num_layers=self.number_layers, batch_first = True, bidirectional = bi_directional) \n",
    "        # in bidirectional encoder we have  forward and backward hidden states\n",
    "        self.encoding_size = self.output_size * 2 if bi_directional else self.output_size\n",
    "        self.combination_layer = nn.Linear(self.encoding_size, self.encoding_size)\n",
    "        # Create affine layer to project to the classes \n",
    "        self.projection = nn.Linear(self.encoding_size, self.output_size)\n",
    "        #dropout layer for regularizetion of a sequence\n",
    "        self.dropout_layer = nn.Dropout(p = dropout)  \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.relu(self.fc1(x))\n",
    "        h, _ = self.fc2(h) # h, _ : as I have 2outputs (tuple), only take the real output [0]. \n",
    "        #print(type(h)) # Underscore throughs away the rest, _ \"I do not care\" variable notation in python\n",
    "        h = self.relu(self.combination_layer(h))\n",
    "        h = self.dropout_layer(h)\n",
    "        h = self.projection(h) \n",
    "        return h\n",
    "\n",
    "#create a network \n",
    "nn_model = Net(input_size, emb_size, output_size,bi_directional, number_layers, dropout)\n",
    "#print(nn_model)\n",
    "#print(list(nn_model.parameters()))\n",
    "\n",
    "\n",
    "# BCE Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss() # class imbalance\n",
    "# criterion = nn.BCEWithLogitsLoss(pos_weight = torch.tensor(round(zeroes/ones,0))) # class imbalance\n",
    "#print(round(zeroes/ones,0))\n",
    "optimizer = optim.Adam(nn_model.parameters(), lr=lr) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Count unique values\n",
    "unique, counts = np.unique(y_val, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "# Count NaN values\n",
    "nan_count = np.isnan(y_val).sum()\n",
    "print(f\"Number of NaN values: {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all nans in X_val with 0\n",
    "X_val[torch.isnan(X_val)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_original = X_val.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_original = X_val.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_extended = X_val.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training loop (full data 3.5 hours)\n",
    "\n",
    "epochs = n_epochs\n",
    "starttime = datetime.now() # datetime object containing current date and time\n",
    "train_losses, validation_losses = [], []\n",
    "best = 0\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    print (\"\\n Epoch [%d] out of %d\" % (epoch + 1, epochs))\n",
    "    running_loss = 0.0\n",
    "    validation_loss = 0.0\n",
    "    roc_auc = 0.0\n",
    "    pr_auc = 0.0\n",
    "    m = 0\n",
    "    \n",
    "    #train\n",
    "    #print(list(nn_model.parameters())[0])\n",
    "    # pbar = tqdm(X_train, desc=f\"Epoch {epoch+1}\")\n",
    "    # for i in pbar:\n",
    "    #     # zero the parameter gradients\n",
    "    #     optimizer.zero_grad() # zero the gradient buffers not to consider gradients of previous iterations\n",
    "    #     X_batch = X_train[m]\n",
    "    #     y_batch = y_train[m]\n",
    "    #     # print(X_batch.shape)\n",
    "    #     # forward + backward + optimize\n",
    "    #     outputs = nn_model(X_batch)\n",
    "    #     outputs = torch.flatten(outputs)\n",
    "    #     y_batch = y_batch.type_as(outputs)\n",
    "    #     loss = criterion(outputs, y_batch)\n",
    "    #     loss.backward()\n",
    "    #     optimizer.step() # Does the update\n",
    "    #     running_loss += loss.item()\n",
    "    #     m +=1\n",
    "    #     pbar.set_postfix({\"Training Loss\": running_loss/len(X_train)})\n",
    "        \n",
    "   \n",
    "    #validation \n",
    "    nn_model.eval()\n",
    "    with torch.no_grad():\n",
    "        v_out = nn_model(X_val) \n",
    "        v_out = torch.flatten(v_out) \n",
    "        y_val = y_val.type_as(v_out)\n",
    "        v_loss = criterion(v_out, y_val)\n",
    "        validation_loss = v_loss.item()\n",
    "        # auc and pr auc\n",
    "        val_prob = torch.nn.Sigmoid() (v_out)\n",
    "        print(type(v_out))\n",
    "        print(v_out)\n",
    "        print(val_prob)\n",
    "        print(y_val)\n",
    "        roc_auc = roc_auc_score(y_val,val_prob) \n",
    "        \n",
    "    validation_losses.append(validation_loss) \n",
    "    train_losses.append(running_loss/len(X_train)) \n",
    "    print(f\"Training loss: {running_loss/len(X_train):.3f}.. \" f\"Validation loss: {validation_loss:.3f}.. \")\n",
    "    print(f\"AUC: {roc_auc:.2f}\")  \n",
    "    nn_model.train()\n",
    "    \n",
    "    \n",
    "    if roc_auc > best:\n",
    "        best = roc_auc\n",
    "        PATH = './LSTMbest.pth' \n",
    "        torch.save(nn_model.state_dict(), PATH) # save the model\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "       \n",
    "print('Finished Training')\n",
    "print(\"starttime =\", starttime)\n",
    "now = datetime.now()\n",
    "print(\"now =\", now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "PATH = './LSTM.pth' \n",
    "torch.save(nn_model.state_dict(), PATH) # save the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on the test set\n",
    "PATH = './LSTM.pth'\n",
    "nn_model.load_state_dict(torch.load(PATH))\n",
    "nn_model.eval()\n",
    "with torch.no_grad():\n",
    "    t_out = nn_model(X_test)\n",
    "    t_out = torch.flatten(t_out)\n",
    "    y_test = y_test.type_as(t_out)\n",
    "    t_loss = criterion(t_out, y_test)\n",
    "    test_loss = t_loss.item()\n",
    "    # auc and pr auc\n",
    "    test_prob = torch.nn.Sigmoid() (t_out)\n",
    "    roc_auc = roc_auc_score(y_test,test_prob) \n",
    "    pr_auc = average_precision_score(y_test,test_prob)\n",
    "    # convert output probabilities to class labels\n",
    "    test_pred = (test_prob > 0.5).float()\n",
    "\n",
    "    # calculate accuracy\n",
    "    accuracy = accuracy_score(y_test.cpu().numpy(), test_pred.cpu().numpy())\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}.. \" f\"ROC AUC: {roc_auc:.2f}.. \" f\"PR AUC: {pr_auc:.2f}.. \")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a freshly initialized model on test\n",
    "nn_model = Net(input_size, emb_size, output_size,bi_directional, number_layers, dropout)\n",
    "# nn_model.load_state_dict(torch.load(PATH))\n",
    "nn_model.eval()\n",
    "with torch.no_grad():\n",
    "    t_out = nn_model(X_test)\n",
    "    t_out = torch.flatten(t_out)\n",
    "    y_test = y_test.type_as(t_out)\n",
    "    t_loss = criterion(t_out, y_test)\n",
    "    test_loss = t_loss.item()\n",
    "    # auc and pr auc\n",
    "    test_prob = torch.nn.Sigmoid() (t_out)\n",
    "    roc_auc = roc_auc_score(y_test,test_prob) \n",
    "    pr_auc = average_precision_score(y_test,test_prob)\n",
    "    print(f\"Test loss: {test_loss:.3f}.. \" f\"ROC AUC: {roc_auc:.2f}.. \" f\"PR AUC: {pr_auc:.2f}.. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './i-Bidir_3_lr_0.001_nodropbest.pth'\n",
    "\n",
    "# save the model\n",
    "#torch.save(nn_model.state_dict(), PATH)\n",
    "\n",
    "# code to load saved model\n",
    "nn_model = Net(input_size, emb_size, output_size,bi_directional, number_layers, dropout)\n",
    "nn_model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test) # single batch with zero padding to the max shape 635208"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next step testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = nn_model(X_test)\n",
    "pred = torch.nn.Sigmoid() (logits)\n",
    "pred = pred.detach().numpy()\n",
    "pred = pred.reshape(-1,1)\n",
    "print(\"Performance on full X_test where it has no batching: is padded to max dimentions. \\n\")\n",
    "print (\"Area Under ROC Curve: %0.2f\" % roc_auc_score(y_test, pred, average = 'micro')  )\n",
    "brier = round(metrics.brier_score_loss(y_test, pred, sample_weight=None, pos_label=None),3)\n",
    "print(\"Brier score : {:.3f}\".format(brier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('padded_lstm.npy', 'wb') as f:\n",
    "    np.save(f, y_test)\n",
    "    np.save(f, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = X_test.shape[1] #133\n",
    "icustays = X_test.shape[0]\n",
    "times = []\n",
    "auc_s = []\n",
    "t = 0\n",
    "\n",
    "while t < timestamps:\n",
    "    times.append(t+1)\n",
    "    row = t\n",
    "    i = 0\n",
    "    prob_t = []\n",
    "    y_t = []\n",
    "    while i < icustays:\n",
    "        prob_t.append(pred[row])\n",
    "        y_t.append(y_test[row])\n",
    "        row += timestamps\n",
    "        i +=1\n",
    "    prob_t = np.array(prob_t).reshape(-1,1)\n",
    "    y_t = np.array(y_t).reshape(-1,1)\n",
    "    auc_s.append(roc_auc_score(y_t, prob_t, average = 'micro'))\n",
    "    t +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.DataFrame(auc_s, columns = ['AUC'])\n",
    "df['Timestamps'] = times\n",
    "#df[120:133]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot \n",
    "sns.lineplot(x=\"Timestamps\", y=\"AUC\", color = 'g',\n",
    "             data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing to LogR, XGB, RF models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = batch(test, test.shape[0]) \n",
    "X_test = X_test[0]\n",
    "y_test = y_test[0]\n",
    "\n",
    "\n",
    "def to_one_label (model, label_list,X_test,index_list):\n",
    "    # evaluate on a test set\n",
    "    labels = np.array(label_list)\n",
    "    labels = labels.reshape(-1,1)\n",
    "    labels = labels.astype(int)\n",
    "    logits = model(X_test)\n",
    "    pred = torch.nn.Sigmoid() (logits)\n",
    "    max_rows = pred.shape[1]\n",
    "    predictions = pred.detach().numpy()\n",
    "    predictions = predictions.reshape(-1,1) \n",
    "    # select 1 per icu stay id by index\n",
    "    prob_1_label = []\n",
    "    row = 0\n",
    "    prev = 0\n",
    "    for i in index_list:\n",
    "        prob_1_label.append(predictions[row+i-prev])\n",
    "        row += pred.shape[1]\n",
    "        prev = i\n",
    "    prob_1_label = np.array(prob_1_label).reshape(-1,1)\n",
    "    \n",
    "    return labels, prob_1_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance (y_test, pred_probabilities):\n",
    "    # performance\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, pred_probabilities)\n",
    "    # compute roc auc\n",
    "    roc_auc = roc_auc_score(y_test, pred_probabilities, average = 'micro')\n",
    "    # compute Precision_Recall curves\n",
    "    precision, recall, _ = precision_recall_curve(y_test, pred_probabilities)\n",
    "    # compute PR_AUC\n",
    "    pr_auc = metrics.auc(recall, precision)\n",
    "       \n",
    "    # I add confusion matrix\n",
    "    optimal_cut_off = round(thresholds[np.argmax(tpr - fpr)],4)\n",
    "    a = np.where(pred_probabilities > optimal_cut_off, 1, 0)\n",
    "    brier = round(metrics.brier_score_loss(y_test, pred_probabilities, sample_weight=None, pos_label=None),3)\n",
    "    predictions = np.where(pred_probabilities > optimal_cut_off, 1, 0)  \n",
    "    \n",
    "    print (\"Area Under ROC Curve: %0.2f\" % roc_auc  )\n",
    "    #print (\"Area Under PR Curve(AP): %0.2f\" % pr_auc  ) \n",
    "    print(\"Brier score : {:.3f}\".format(brier))\n",
    "    #print('Accuracy for Classifier : {:.2f}'.format(accuracy_score(y_test, predictions)))\n",
    "    #print('Cut off: ' + str(optimal_cut_off))\n",
    "    matrix = metrics.confusion_matrix(y_test, a, labels=None, normalize=None)\n",
    "    #print(str(matrix))\n",
    "    \n",
    "    #f.write(\"\\n Area Under ROC Curve: \" +str(roc_auc))\n",
    "    #f.write(\"\\n Area Under PR Curve(AP): \" + str(pr_auc))\n",
    "    #f.write(\"\\n Brier score: \" +str(brier))\n",
    "    #f.write('\\n Accuracy for Classifier '+str(round((accuracy_score(labels, predictions)),3)))\n",
    "    #f.write(\"\\n Cut off: \" +str(optimal_cut_off))\n",
    "    #f.write(str(matrix))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels, prob_1_label = to_one_label (nn_model, label_list,X_test,index_list)\n",
    "performance(labels,prob_1_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save labels, prob_1_label\n",
    "\n",
    "with open('test.npy', 'wb') as f:\n",
    "    #np.save(f, labels)\n",
    "    np.save(f, prob_1_label)\n",
    "with open('test.npy', 'rb') as f:\n",
    "    #lstm_labels = np.load(f)\n",
    "    lstm_prob = np.load(f)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To apply integrated gradients, we first create an IntegratedGradients object, providing the model object.\n",
    "ig = IntegratedGradients(nn_model)\n",
    "# To compute the integrated gradients, we use the attribute method of the IntegratedGradients object. The method takes\n",
    "# tensor(s) of input examples (matching the forward function of the model), and returns the input attributions for the\n",
    "# given examples. A target index, defining the index of the output for which gradients are computed is 1, \n",
    "# corresponding to AKI (1/0).\n",
    "\n",
    "#The input tensor provided should require grad, so we call requires_grad_ on the tensor. The attribute method also \n",
    "# takes a baseline, which is the starting point from which gradients are integrated. The default value is just the \n",
    "# 0 tensor, which is a reasonable baseline / default for this task.\n",
    "\n",
    "#The returned values of the attribute method are the attributions, which match the size of the given inputs, and delta,\n",
    "# which approximates the error between the approximated integral and true integral.\n",
    "print(datetime.now())\n",
    "X_test.requires_grad_()\n",
    "attr, delta = ig.attribute(X_test,target=1, return_convergence_delta=True)\n",
    "attr = attr.detach().numpy()\n",
    "attr= np.reshape(attr,(-1,35))\n",
    "importances = np.mean(attr, axis=0)\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr[:,0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr[:,4].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_importances(feature_names, importances, title=\"LSTM Average Feature Importances\", axis_title=\"Features\"):\n",
    "    print(title)\n",
    "    i = 0\n",
    "    while i < features:\n",
    "        print(feature_names[i], \": \", '%.3f'%(importances[i]))\n",
    "        i +=1\n",
    "    x_pos = (np.arange(len(feature_names)))\n",
    "    \n",
    "visualize_feature_importances(feature_names, importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_df =  pd.DataFrame(importances, columns = ['Feature Importance'])\n",
    "lstm_df['Features'] = feature_names\n",
    "lstm_df = lstm_df.sort_values(by = ['Feature Importance'], ascending = False, ignore_index = True)\n",
    "#lstm_df[\"Feature Importance\"] =  lstm_df[\"Feature Importance\"]\n",
    "#lstm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_df[\"Feature Importance\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.barplot(x='Feature Importance', y='Features', data=lstm_df)\n",
    "ax = sns.barplot(x='Feature Importance', y='Features', data=lstm_df, color = 'grey')\n",
    "ax.set_xlabel('Feature Importance', fontsize = 15)\n",
    "ax.set_ylabel(\"Features\",fontsize=15)\n",
    "ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize = 6)\n",
    "plt.title('LSTM feature Importances')\n",
    "plt.savefig('LSTM_feature_importance_grey.png', dpi = 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_df['abs'] = abs(lstm_df['Feature Importance'])\n",
    "lstm_df = lstm_df.sort_values(by = ['abs'], ascending = False, ignore_index = True)\n",
    "lstm_df_10 = lstm_df.head(10)\n",
    "#lstm_df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.barplot(x='Feature Importance', y='Features', data=lstm_df_10, palette=\"mako\")\n",
    "\n",
    "ax = sns.barplot(x='Feature Importance', y='Features', data=lstm_df_10, color = 'darkgreen')\n",
    "ax.set_xlabel('Feature Importance', fontsize = 15)\n",
    "ax.set_ylabel(\"Features\",fontsize=15)\n",
    "ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize = 10)\n",
    "plt.title('LSTM top 10 features by feature importance')\n",
    "plt.savefig('LSTM_top10_feature_importance_darkgreen.png', dpi = 300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graphs (y_test,pred_probabilities, classifier_name, plot_name, algorithm):\n",
    "    \n",
    "    def bin_total(y_true, y_prob, n_bins):\n",
    "        bins = np.linspace(0., 1. + 1e-8, n_bins + 1)\n",
    "\n",
    "        # In sklearn.calibration.calibration_curve, the last value in the array is always 0.\n",
    "        binids = np.digitize(y_prob, bins) - 1\n",
    "\n",
    "        return np.bincount(binids, minlength=len(bins))\n",
    "\n",
    "    def missing_bin(bin_array):\n",
    "        midpoint = \" \"    \n",
    "        if bin_array[0]==0:\n",
    "            midpoint = \"5%, \"\n",
    "        if bin_array[1]==0:\n",
    "            midpoint = midpoint + \"15%, \"\n",
    "        if bin_array[2]==0:\n",
    "            midpoint = midpoint + \"25%, \"\n",
    "        if bin_array[3]==0:\n",
    "            midpoint = midpoint + \"35%, \" \n",
    "        if bin_array[4]==0:\n",
    "            midpoint = midpoint + \"45%, \"\n",
    "        if bin_array[5]==0:\n",
    "            midpoint = midpoint + \"55%, \"\n",
    "        if bin_array[6]==0:\n",
    "            midpoint = midpoint + \"65%, \"\n",
    "        if bin_array[7]==0:\n",
    "            midpoint = midpoint + \"75%, \"\n",
    "        if bin_array[8]==0:\n",
    "            midpoint = midpoint + \"85%, \"\n",
    "        if bin_array[9]==0:\n",
    "            midpoint = midpoint + \"95%, \"\n",
    "        return \"The missing bins have midpoint values of \"+ str(midpoint)\n",
    "    \n",
    "    # performance\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, pred_probabilities)\n",
    "    # compute roc auc\n",
    "    roc_auc = roc_auc_score(y_test, pred_probabilities, average = 'micro')\n",
    "    # compute Precision_Recall curves\n",
    "    precision, recall, _ = precision_recall_curve(y_test, pred_probabilities)\n",
    "    # compute PR_AUC\n",
    "    pr_auc = metrics.auc(recall, precision)\n",
    "\n",
    "    # compute calibration curve\n",
    "    LR_y, LR_x = calibration_curve(y_test, pred_probabilities, n_bins=10)\n",
    "    #find out which one are the missing bins\n",
    "    bin_array = bin_total(y_test, pred_probabilities , n_bins=10)\n",
    "    print(missing_bin(bin_array))\n",
    "\n",
    "    print(\"plot curves and save in one png file\")\n",
    "    #save three plots in one png file\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, figsize=(7, 24))\n",
    "    fig.subplots_adjust(wspace=0.3, hspace= 0.3)\n",
    "    fig.suptitle('Evaluation of '+ plot_name)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, pred_probabilities)\n",
    "    \n",
    "    # plot roc curve\n",
    "    ax1.plot(fpr, tpr,'C2', label=algorithm+\" \"+\"Classifier \" + str(classifier_name) + \", auc=\" +str(round(roc_auc,2)))\n",
    "    ax1.title.set_text('ROC AUC')\n",
    "    ax1.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "\n",
    "    # plot PR curve\n",
    "    ax2.plot(recall, precision,'C2', label=algorithm+\" \"+\"Classifier \" + str(classifier_name) + \", auc=\"+str(round(pr_auc,2)))\n",
    "    ax2.title.set_text('PR AUC')\n",
    "    ax2.set(xlabel='Recall', ylabel='Precision')\n",
    "    ax2.legend(loc=\"lower right\")\n",
    "\n",
    "    # plot calibration curve\n",
    "    ax3.plot(LR_x, LR_y, 'C2',marker='o', linewidth=1, label='LR')\n",
    "    line = mlines.Line2D([0, 1], [0, 1], color='black')\n",
    "    transform = ax3.transAxes\n",
    "    line.set_transform(transform)\n",
    "    ax3.add_line(line)\n",
    "    ax3.title.set_text('Calibration plot for '+str(plot_name))\n",
    "    ax3.set(xlabel= 'Predicted probability', ylabel= 'True probability in each bin')\n",
    "    ax3.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.savefig(plot_name+\".png\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution(pred_probabilities, y_test, dist_name):\n",
    "    #probabilities distributions graphs\n",
    "    true_1 = pd.DataFrame(pred_probabilities, columns=['Predicted probabilities'])\n",
    "    true_1['labels'] = y_test.tolist()\n",
    "    true_0 = true_1.copy(deep = True) \n",
    "    indexNames = true_1[true_1['labels'] == 0].index\n",
    "    true_1.drop(indexNames , inplace=True)\n",
    "    indexNames = true_0[ true_0['labels'] == 1 ].index\n",
    "    true_0.drop(indexNames , inplace=True)\n",
    "    true_1.drop(columns=['labels'], inplace = True)\n",
    "    true_0.drop(columns=['labels'], inplace = True)\n",
    "    \n",
    "    sns.distplot(true_1['Predicted probabilities'], hist = False, kde = True,\n",
    "                 kde_kws = {'shade': True, 'linewidth': 3,\"color\": \"g\"}, label = 'Class 1')\n",
    "    plt.ylabel('Density')\n",
    "    sns.distplot(true_0['Predicted probabilities'], hist = False, kde = True,\n",
    "                     kde_kws = {'shade': True, 'linewidth': 3}, label = 'Class 0')\n",
    "    plt.title('Density Plot'+ dist_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distribution(prob_1_label, labels.flatten(), \" Bidirectional LSTM no imputation \")\n",
    "plt.savefig('dist_LSTM_bi_NOimp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_name = \"None vs. Any AKI\"    ###change every time #Moderate vs. Severe #None vs. Any #Others vs. Severe\n",
    "plot_name = \"LSTM NO imputation\"\n",
    "build_graphs(labels.flatten(), prob_1_label.flatten(), classifier_name, plot_name, \"LSTM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(labels, prob_1_label)\n",
    "fpr, tpr, thresholds = roc_curve(labels, prob_1_label)\n",
    "optimal_cut_off = round(thresholds[np.argmax(tpr - fpr)],2)\n",
    "prediction = np.where(prob_1_label > optimal_cut_off, 1, 0)\n",
    "f1 = f1_score(labels,prediction)\n",
    "prauc =auc(recall, precision)\n",
    "print('F1 = %.3f, PR auc =%.3f' % (f1,prauc))\n",
    "\n",
    "# plot the precision-recall curves\n",
    "no_skill = len(labels[labels==1]) / len(labels)\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "plt.plot(recall,precision, marker='.', label='LSTM')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search grid \n",
    "layers = [1,2,3]\n",
    "l_rate = [0.001, 0.0001]\n",
    "drop = [0,0.2]\n",
    "bidirectionality = [True,False]\n",
    "#loops count\n",
    "hypercount = 0\n",
    "# static parameters\n",
    "n_epochs = 80\n",
    "emb_size = round(features/1)\n",
    "input_size = features\n",
    "output_size = 1\n",
    "###############################\n",
    "\n",
    "f = open('lstm_no_imp_uni.txt', 'w+') #change with or without imp\n",
    "\n",
    "for q1 in bidirectionality:\n",
    "    for q2 in layers:\n",
    "        for q3 in drop:\n",
    "            for q4 in l_rate:\n",
    "                hypercount +=1\n",
    "                name = \"i-Bidir_\" if q1 else \"i-Onedir_\"\n",
    "                name = name+str(q2) + \"_lr_\"+str(q4)\n",
    "                name = name+\"_drop\"+str(q3) if q3 == 0.2 else name+\"_nodrop\"\n",
    "                #set parameters\n",
    "                bi_directional = q1\n",
    "                lr = q4\n",
    "                number_layers = q2\n",
    "                dropout = q3 # dropout\n",
    "                print('hypercount: %d' % hypercount)\n",
    "                print('\\n')\n",
    "                print(name)\n",
    "                f.write('\\n\\n' + str(name)+ '\\n\\n')\n",
    "                    \n",
    "                # create the NN\n",
    "                class Net(nn.Module):\n",
    "                    def __init__(self, input_size, emb_size, output_size, bi_directional, number_layers, dropout):\n",
    "                        super(Net, self).__init__()\n",
    "                        self.input_size = input_size\n",
    "                        self.emb_size = emb_size \n",
    "                        self.output_size = output_size\n",
    "                        self.number_layers = number_layers\n",
    "                        self.fc1 = nn.Linear(self.input_size, self.emb_size, bias = True) # I can have a few (IV) within this line - documentation        \n",
    "                        self.fc2 = nn.LSTM(self.emb_size, self.output_size,num_layers=self.number_layers, batch_first = True, bidirectional = bi_directional) \n",
    "                        # in bidirectional encoder we have  forward and backward hidden states\n",
    "                        self.encoding_size = self.output_size * 2 if bi_directional else self.output_size\n",
    "                        self.combination_layer = nn.Linear(self.encoding_size, self.encoding_size)\n",
    "                        # Create affine layer to project to the classes \n",
    "                        self.projection = nn.Linear(self.encoding_size, self.output_size)\n",
    "                        #dropout layer for regularizetion of a sequence\n",
    "                        self.dropout_layer = nn.Dropout(p = dropout)  \n",
    "                        self.relu = nn.ReLU()\n",
    "\n",
    "                    def forward(self, x):\n",
    "                        h = self.relu(self.fc1(x))\n",
    "                        h, _ = self.fc2(h) # h, _ : as I have 2outputs (tuple), only take the real output [0]. \n",
    "                        #print(type(h)) # Underscore throughs away the rest, _ \"I do not care\" variable notation in python\n",
    "                        h = self.relu(self.combination_layer(h))\n",
    "                        h = self.dropout_layer(h)\n",
    "                        h = self.projection(h) \n",
    "                        return h\n",
    "\n",
    "                #create a network \n",
    "                nn_model = Net(input_size, emb_size, output_size,bi_directional, number_layers, dropout)\n",
    "                print(nn_model)\n",
    "                #print(list(nn_model.parameters()))\n",
    "                \n",
    "                # BCE Loss and optimizer\n",
    "                criterion = nn.BCEWithLogitsLoss(pos_weight = torch.tensor(round(zeroes/ones,0))) # class imbalance\n",
    "                #print(round(zeroes/ones,0))\n",
    "                optimizer = optim.Adam(nn_model.parameters(), lr=lr) \n",
    "    \n",
    "    \n",
    "                # TRAINING LOOP \n",
    "                epochs = n_epochs\n",
    "                starttime = datetime.now() # datetime object containing current date and time\n",
    "                train_losses, validation_losses = [], []\n",
    "                best = 0\n",
    "                patience = 0\n",
    "                old_auc = 0\n",
    "                old_pr = 0\n",
    "\n",
    "                for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "                    print (\"\\n Epoch [%d] out of %d\" % (epoch + 1, epochs))\n",
    "                    running_loss = 0.0\n",
    "                    validation_loss = 0.0\n",
    "                    roc_auc = 0.0\n",
    "                    pr_auc = 0.0\n",
    "                    m = 0\n",
    "                    \n",
    "                    #train\n",
    "                    #print(list(nn_model.parameters())[0])\n",
    "                    for i in X_train:\n",
    "                        # zero the parameter gradients\n",
    "                        optimizer.zero_grad() # zero the gradient buffers not to consider gradients of previous iterations\n",
    "                        X_batch = X_train[m]\n",
    "                        y_batch = y_train[m]\n",
    "                        # forward + backward + optimize\n",
    "                        outputs = nn_model(X_batch)\n",
    "                        outputs = torch.flatten(outputs)\n",
    "                        y_batch = y_batch.type_as(outputs)\n",
    "                        loss = criterion(outputs, y_batch)\n",
    "                        loss.backward()\n",
    "                        optimizer.step() # Does the update\n",
    "                        running_loss += loss.item()\n",
    "                        m +=1\n",
    "                    #validation \n",
    "                    nn_model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        v_out = nn_model(X_val) \n",
    "                        v_out = torch.flatten(v_out) \n",
    "                        y_val = y_val.type_as(v_out)\n",
    "                        v_loss = criterion(v_out, y_val)\n",
    "                        validation_loss = v_loss.item()\n",
    "                        # auc and pr auc\n",
    "                        val_prob = torch.nn.Sigmoid() (v_out)\n",
    "                        precision, recall, thresholds = precision_recall_curve(y_val, val_prob)\n",
    "                        pr_auc = auc(recall, precision)\n",
    "                        roc_auc = roc_auc_score(y_val,val_prob) \n",
    "\n",
    "                    validation_losses.append(validation_loss) \n",
    "                    train_losses.append(running_loss/len(X_train)) \n",
    "                    print(f\"Training loss: {running_loss/len(X_train):.3f}.. \" f\"Validation loss: {validation_loss:.3f}.. \")\n",
    "                    print(f\"AUC: {roc_auc:.2f} \" f\"PR AUC: {pr_auc:.2f} \")  \n",
    "                    nn_model.train()\n",
    "\n",
    "                    \n",
    "                    if roc_auc > best:\n",
    "                        best = roc_auc\n",
    "                        PATH1 = './'+str(name)+'best.pth' \n",
    "                        torch.save(nn_model.state_dict(), PATH1) # save the model\n",
    "                    else:\n",
    "                        pass\n",
    "                    \n",
    "                    if roc_auc == old_auc and pr_auc==old_pr:\n",
    "                        patience +=1\n",
    "                    old_auc = roc_auc\n",
    "                    old_pr = pr_auc\n",
    "                    if patience ==10:\n",
    "                        print(\"out of patience\")\n",
    "                        break\n",
    "\n",
    "                print('\\n Finished Training')\n",
    "                print(\"starttime =\", starttime)\n",
    "                now = datetime.now()\n",
    "                print(\"endtime =\", now)\n",
    "                # end of training loop\n",
    "                \n",
    "                PATH2 = './'+str(name)+'last.pth' \n",
    "                torch.save(nn_model.state_dict(), PATH2) # save the model\n",
    "                print('\\n Last model \\n')\n",
    "                labels, probs = to_one_label(nn_model,label_list,X_test,index_list)\n",
    "                performance (nn_model, labels, probs)\n",
    "                \n",
    "                #load the best model\n",
    "                best_model = Net(input_size, emb_size, output_size,bi_directional, number_layers, dropout)\n",
    "                best_model.load_state_dict(torch.load(PATH1))\n",
    "                print('\\n Best model \\n')\n",
    "                labels, probs = to_one_label(best_model,label_list,X_test,index_list)\n",
    "                performance (best_model, labels, probs)\n",
    "f.close() \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medinf",
   "language": "python",
   "name": "medinf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
