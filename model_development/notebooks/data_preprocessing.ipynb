{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/horse/ws/jori152b-medinf/KP_MedInf\n",
      "/data/horse/ws/jori152b-medinf/KP_MedInf/notebooks\n"
     ]
    }
   ],
   "source": [
    "# only for taurus\n",
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir(\"notebooks\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths and separator\n",
    "DATA_PATH_stages = \"../data/extracted/kdigo_stages_measured.csv\"\n",
    "DATA_PATH_labs = \"../data/extracted/labs_original.csv\"\n",
    "DATA_PATH_labs_extended = \"../data/extracted/labs_extended.csv\"\n",
    "DATA_PATH_labs_new = \"../data/extracted/labs_new.csv\"\n",
    "# DATA_PATH_vitals = \"../data/extracted/vitals-kdigo_stages_measured.csv\"\n",
    "DATA_PATH_vitals = \"../data/extracted/vitals.csv\"\n",
    "# DATA_PATH_vents = \"../data/extracted/vents-vasopressor-sedatives-kdigo_stages_measured.csv\"\n",
    "DATA_PATH_vents = \"../data/extracted/vents_vasopressor_sedatives.csv\"\n",
    "# DATA_PATH_detail = \"../data/extracted/icustay_detail-kdigo_stages_measured.csv\"\n",
    "DATA_PATH_detail = \"../data/extracted/icustay_detail.csv\"\n",
    "DATA_PATH_heightweight = \"../data/extracted/heightweight.csv\"\n",
    "DATA_PATH_calcium = \"../data/extracted/calcium.csv\"\n",
    "DATA_PATH_inr_max = \"../data/extracted/inr_max.csv\"\n",
    "SEPARATOR = \";\"\n",
    "\n",
    "# Constants\n",
    "IMPUTE_EACH_ID = False\n",
    "IMPUTE_COLUMN = False\n",
    "TESTING = False\n",
    "TEST_SIZE = 0.05\n",
    "SPLIT_SIZE = 0.2\n",
    "MAX_DAYS = 35\n",
    "CLASS1 = True\n",
    "ALL_STAGES = False\n",
    "MAX_FEATURE_SET = True\n",
    "FIRST_TURN_POS = True\n",
    "TIME_SAMPLING = True\n",
    "SAMPLING_INTERVAL = '6H'\n",
    "RESAMPLE_LIMIT = 16\n",
    "MOST_COMMON = False\n",
    "IMPUTE_METHOD = 'most_frequent'\n",
    "FILL_VALUE = 0\n",
    "ADULTS_MIN_AGE = 18\n",
    "ADULTS_MAX_AGE = 120\n",
    "NORMALIZATION = 'min-max'\n",
    "HOURS_AHEAD = 48\n",
    "NORM_TYPE = 'min_max'\n",
    "RANDOM = 42\n",
    "\n",
    "def filter_by_length_of_stay(X):\n",
    "    drop_list = []\n",
    "    long_stays = X.groupby(['icustay_id']).apply(lambda group: (group['charttime'].max() - group['charttime'].min()).total_seconds() / (24 * 60 * 60) > MAX_DAYS)\n",
    "\n",
    "    for icustay_id, is_long in long_stays.items():\n",
    "        if is_long:\n",
    "            max_time = X[X['icustay_id'] == icustay_id]['charttime'].max() - pd.to_timedelta(MAX_DAYS, unit='D')\n",
    "            X = X[~((X['icustay_id'] == icustay_id) & (X['charttime'] < max_time))]\n",
    "\n",
    "    short_stays = X.groupby(['icustay_id']).apply(lambda group: (group['charttime'].max() - group['charttime'].min()).total_seconds() / (24 * 60 * 60) < (HOURS_AHEAD/24))\n",
    "    drop_list = short_stays[short_stays].index.tolist()\n",
    "\n",
    "    X = X[~X.icustay_id.isin(drop_list)]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "3737147\n",
      "aki_stage\n",
      "0    3000795\n",
      "2     353266\n",
      "3     207759\n",
      "1     175327\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "X = pd.read_csv(DATA_PATH_stages, sep=SEPARATOR)\n",
    "X.drop([\"aki_stage_creat\", \"aki_stage_uo\"], axis=1, inplace=True)\n",
    "X = X.dropna(how='all', subset=['creat', 'uo_rt_6hr', 'uo_rt_12hr', 'uo_rt_24hr', 'aki_stage'])\n",
    "X['charttime'] = pd.to_datetime(X['charttime'])\n",
    "\n",
    "print(len(X))\n",
    "print(X['aki_stage'].value_counts())\n",
    "\n",
    "dataset_detail = pd.read_csv(DATA_PATH_detail, sep=SEPARATOR)\n",
    "# original data\n",
    "# dataset_detail.drop(['dod', 'admittime', 'dischtime', 'los_hospital', 'ethnicity', \n",
    "#                      'hospital_expire_flag', 'hospstay_seq', 'first_hosp_stay', 'intime', \n",
    "#                      'outtime', 'los_icu', 'icustay_seq', 'first_icu_stay'], axis=1, inplace=True)\n",
    "# out data\n",
    "dataset_detail.drop(['dod', 'admittime', 'dischtime', 'los_hospital', 'ethnicity', \n",
    "                     'hospital_expire_flag', 'hospstay_seq', 'first_hosp_stay', 'intime', \n",
    "                     'outtime', 'los_icu', 'icustay_seq', 'first_icu_stay', 'ethnicity_grouped'], axis=1, inplace=True)\n",
    "\n",
    "# dataset_labs = pd.read_csv(DATA_PATH_labs, sep=SEPARATOR)\n",
    "# dataset_labs = dataset_labs.dropna(subset=['charttime']).dropna(subset=dataset_labs.columns[4:], how='all')\n",
    "# dataset_labs['charttime'] = pd.to_datetime(dataset_labs['charttime'])\n",
    "# dataset_labs = dataset_labs.sort_values(by=['icustay_id', 'charttime'])\n",
    "# dataset_labs.drop(['albumin_min', 'albumin_max','bilirubin_min', 'bilirubin_max','bands_min', 'bands_max',\n",
    "#                    'lactate_min', 'lactate_max','platelet_min', 'platelet_max','ptt_min', 'ptt_max', \n",
    "#                    'inr_min', 'inr_max', 'pt_min', 'pt_max'], axis = 1, inplace = True)\n",
    "# # Calculate mean for each pair and drop original columns\n",
    "# column_pairs = [('aniongap_min', 'aniongap_max'), ('albumin_min', 'albumin_max'), \n",
    "#                 ('bands_min', 'bands_max'), ('bicarbonate_min', 'bicarbonate_max'), \n",
    "#                 ('bilirubin_min', 'bilirubin_max'), ('creatinine_min', 'creatinine_max'), \n",
    "#                 ('chloride_min', 'chloride_max'), ('glucose_min', 'glucose_max'), \n",
    "#                 ('hematocrit_min', 'hematocrit_max'), ('hemoglobin_min', 'hemoglobin_max'), \n",
    "#                 ('lactate_min', 'lactate_max'), ('platelet_min', 'platelet_max'), \n",
    "#                 ('potassium_min', 'potassium_max'), ('ptt_min', 'ptt_max'), \n",
    "#                 ('inr_min', 'inr_max'), ('pt_min', 'pt_max'), ('sodium_min', 'sodium_max'), \n",
    "#                 ('bun_min', 'bun_max'), ('wbc_min', 'wbc_max')]\n",
    "\n",
    "# for min_col, max_col in column_pairs:\n",
    "#     try:\n",
    "#         mean_col = min_col.rsplit('_', 1)[0] + '_mean'\n",
    "#         dataset_labs[mean_col] = dataset_labs[[min_col, max_col]].mean(axis=1)\n",
    "#         dataset_labs.drop([min_col, max_col], axis=1, inplace=True)\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "dataset_labs_extended = pd.read_csv(DATA_PATH_labs_extended, sep=SEPARATOR)\n",
    "dataset_labs_extended = dataset_labs_extended.dropna(subset=['charttime']).dropna(subset=dataset_labs_extended.columns[4:], how='all')\n",
    "dataset_labs_extended['charttime'] = pd.to_datetime(dataset_labs_extended['charttime'])\n",
    "dataset_labs_extended = dataset_labs_extended.sort_values(by=['icustay_id', 'charttime'])\n",
    "\n",
    "column_pairs_extended = [('aniongap_min', 'aniongap_max'), ('albumin_min', 'albumin_max'), \n",
    "                ('bands_min', 'bands_max'), ('bicarbonate_min', 'bicarbonate_max'), \n",
    "                ('bilirubin_min', 'bilirubin_max'), ('creatinine_min', 'creatinine_max'), \n",
    "                ('chloride_min', 'chloride_max'), ('glucose_min', 'glucose_max'), \n",
    "                ('hematocrit_min', 'hematocrit_max'), ('hemoglobin_min', 'hemoglobin_max'), \n",
    "                ('lactate_min', 'lactate_max'), ('platelet_min', 'platelet_max'), \n",
    "                ('potassium_min', 'potassium_max'), ('ptt_min', 'ptt_max'), \n",
    "                ('inr_min', 'inr_max'), ('pt_min', 'pt_max'), ('sodium_min', 'sodium_max'), \n",
    "                ('bun_min', 'bun_max'), ('wbc_min', 'wbc_max'), \n",
    "                ('gfr_min', 'gfr_max'), ('phosphate_min', 'phosphate_max'),('uric_acid_min', 'uric_acid_max'), \n",
    "                ('calcium_min', 'calcium_max')]\n",
    "\n",
    "\n",
    "for min_col, max_col in column_pairs_extended:\n",
    "    mean_col = min_col.rsplit('_', 1)[0] + '_mean'\n",
    "    dataset_labs_extended[mean_col] = dataset_labs_extended[[min_col, max_col]].mean(axis=1)\n",
    "    dataset_labs_extended.drop([min_col, max_col], axis=1, inplace=True)\n",
    "dataset_labs_extended.drop(['gfr_mean'], axis=1, inplace=True)\n",
    "\n",
    "dataset_vitals = pd.read_csv(DATA_PATH_vitals, sep=SEPARATOR)\n",
    "dataset_vents = pd.read_csv(DATA_PATH_vents, sep=SEPARATOR)\n",
    "dataset_vitals.drop([\"heartrate_min\", \"heartrate_max\", \"sysbp_min\", \"sysbp_max\", \"diasbp_min\", \"diasbp_max\",\n",
    "                        'meanbp_min', 'meanbp_max', 'tempc_min', 'tempc_max', \"resprate_min\", \"resprate_max\", \n",
    "                        \"spo2_min\", \"spo2_max\", \"glucose_min\", \"glucose_max\"], axis=1, inplace=True)\n",
    "dataset_vitals['charttime'] = pd.to_datetime(dataset_vitals['charttime'])\n",
    "dataset_vents['charttime'] = pd.to_datetime(dataset_vents['charttime'])\n",
    "dataset_vitals = dataset_vitals.dropna(subset=dataset_vitals.columns[4:], how='all')\n",
    "dataset_vitals = dataset_vitals.sort_values(by=['icustay_id', 'charttime'])\n",
    "dataset_vents = dataset_vents.sort_values(by=['icustay_id', 'charttime'])\n",
    "\n",
    "dataset_heightweight = pd.read_csv(DATA_PATH_heightweight, sep=SEPARATOR)\n",
    "dataset_heightweight = dataset_heightweight.dropna(subset=['icustay_id', 'height_first', 'weight_first'], how='all')\n",
    "dataset_heightweight = dataset_heightweight.sort_values(by=['icustay_id'])\n",
    "\n",
    "dataset_calcium = pd.read_csv(DATA_PATH_calcium, sep=SEPARATOR)\n",
    "dataset_calcium.drop([\"hadm_id\"], axis=1, inplace=True)\n",
    "dataset_calcium['charttime'] = pd.to_datetime(dataset_calcium['charttime'])\n",
    "dataset_calcium = dataset_calcium.sort_values(by=['icustay_id', 'charttime'])\n",
    "dataset_calcium.drop([\"subject_id\"], axis=1, inplace=True)\n",
    "\n",
    "dataset_inr_max = pd.read_csv(DATA_PATH_inr_max, sep=SEPARATOR)\n",
    "dataset_inr_max.drop([\"hadm_id\", \"subject_id\"], axis=1, inplace=True)\n",
    "dataset_inr_max = dataset_inr_max.sort_values(by=['icustay_id'])\n",
    "\n",
    "\n",
    "\n",
    "# Merge datasets\n",
    "if MAX_FEATURE_SET:\n",
    "    # X = X.merge(dataset_labs, on=[\"icustay_id\", \"charttime\"], how=\"outer\")\n",
    "    X = X.merge(dataset_labs_extended, on=[\"icustay_id\", \"charttime\"], how=\"outer\")\n",
    "    X = X.merge(dataset_vitals, on=[\"icustay_id\", \"charttime\", \"subject_id\", \"hadm_id\"], how=\"outer\")\n",
    "    X = X.merge(dataset_vents, on=[\"icustay_id\", \"charttime\"], how=\"outer\")\n",
    "    X.drop([\"subject_id\"], axis=1, inplace=True)\n",
    "    X = X.merge(dataset_calcium, on=[\"icustay_id\", \"charttime\"], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['icustay_id', 'charttime', 'creat', 'uo_rt_6hr', 'uo_rt_12hr',\n",
       "       'uo_rt_24hr', 'aki_stage', 'hadm_id', 'aniongap_mean', 'albumin_mean',\n",
       "       'bands_mean', 'bicarbonate_mean', 'bilirubin_mean', 'creatinine_mean',\n",
       "       'chloride_mean', 'glucose_mean_x', 'hematocrit_mean', 'hemoglobin_mean',\n",
       "       'lactate_mean', 'platelet_mean', 'potassium_mean', 'ptt_mean',\n",
       "       'inr_mean', 'pt_mean', 'sodium_mean', 'bun_mean', 'wbc_mean',\n",
       "       'phosphate_mean', 'uric_acid_mean', 'calcium_mean', 'heartrate_mean',\n",
       "       'sysbp_mean', 'diasbp_mean', 'meanbp_mean', 'resprate_mean',\n",
       "       'tempc_mean', 'spo2_mean', 'glucose_mean_y', 'vent', 'vasopressor',\n",
       "       'sedative', 'calcium'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject_id', 'hadm_id', 'icustay_id', 'gender', 'admission_age'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_detail.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject_id', 'icustay_id', 'charttime', 'calcium'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_calcium.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering patients by age and length of stay...\n"
     ]
    }
   ],
   "source": [
    "print(\"Filtering patients by age and length of stay...\")\n",
    "# Filtering patients by age and length of stay\n",
    "dataset_detail = dataset_detail[dataset_detail['admission_age'] >= ADULTS_MIN_AGE]\n",
    "adults_icustay_id_list = dataset_detail['icustay_id'].unique()\n",
    "X = X[X.icustay_id.isin(adults_icustay_id_list)].sort_values(by=['icustay_id', 'charttime'])\n",
    "\n",
    "X = filter_by_length_of_stay(X)\n",
    "dataset_detail = dataset_detail[dataset_detail.icustay_id.isin(X['icustay_id'].unique())].sort_values(by=['icustay_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['aki_stage']\n",
    "skip = ['icustay_id', 'charttime', 'aki_stage']\n",
    "discrete_feat = ['sedative', 'vasopressor', 'vent', 'hadm_id']\n",
    "skip.extend(discrete_feat)    \n",
    "numeric_feat = list(X.columns.difference(skip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "X.to_csv('../data/analysis/data_preprocessed_filtered_before_resampling.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('../data/analysis/data_preprocessed_extended__filtered_before_resampling.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## looped dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_INTERVALS = ['1H', '2H', '3H', '4H', '6H']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_detail = dataset_detail[dataset_detail['icustay_id'].isin(X['icustay_id'].unique())].sort_values(by=['icustay_id'])\n",
    "try:\n",
    "    # theirs\n",
    "    dataset_detail = pd.get_dummies(dataset_detail, columns=['gender', 'ethnicity_grouped'])\n",
    "except:\n",
    "    #ours\n",
    "    dataset_detail = pd.get_dummies(dataset_detail, columns=['gender'])\n",
    "dataset_detail.drop(['subject_id', 'hadm_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['icustay_id', 'admission_age', 'gender_F', 'gender_M'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_detail.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_834289/3017786234.py:7: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  X_resampled = X.set_index('charttime').groupby('icustay_id').resample(SAMPLING_INTERVAL)\n"
     ]
    }
   ],
   "source": [
    "# saving every sampling interval\n",
    "# Resampling\n",
    "for SAMPLING_INTERVAL in SAMPLING_INTERVALS:\n",
    "    if TIME_SAMPLING:\n",
    "        \n",
    "        # Set index and group by 'icustay_id' before resampling\n",
    "        X_resampled = X.set_index('charttime').groupby('icustay_id').resample(SAMPLING_INTERVAL)\n",
    "        \n",
    "        # Resample and aggregate features\n",
    "        if MAX_FEATURE_SET:\n",
    "            X_discrete = X_resampled[discrete_feat].max().fillna(FILL_VALUE).astype(np.int64)\n",
    "        X_numeric = X_resampled[numeric_feat].mean()\n",
    "        X_label = X_resampled['aki_stage'].max()\n",
    "\n",
    "        print(\"Merging sampled features\")\n",
    "        try:\n",
    "            X_resampled = pd.concat([X_numeric, X_discrete, X_label], axis=1).reset_index()\n",
    "        except:\n",
    "            X_resampled = pd.concat([X_numeric, X_label], axis=1).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "    # Forward fill again after resampling\n",
    "    X_resampled['aki_stage'] = X_resampled.groupby('icustay_id')['aki_stage'].ffill(limit=RESAMPLE_LIMIT).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "    # Ensure binary values (convert any positive number to 1)\n",
    "    X_resampled['aki_stage'] = (X_resampled['aki_stage'] > 0).astype(int)\n",
    "\n",
    "    # Shifting labels\n",
    "    shift_steps = HOURS_AHEAD // int(SAMPLING_INTERVAL[:-1])\n",
    "    X_resampled['aki_stage'] = X_resampled.groupby('icustay_id')['aki_stage'].shift(-shift_steps)\n",
    "    X_resampled = X_resampled.dropna(subset=['aki_stage'])\n",
    "\n",
    "    # Merging not time-dependent data\n",
    "\n",
    "    X_resampled = X_resampled.merge(dataset_detail, on='icustay_id')\n",
    "    X_resampled = X_resampled.merge(dataset_heightweight, on='icustay_id')\n",
    "    X_resampled = X_resampled.merge(dataset_inr_max, on='icustay_id')\n",
    "\n",
    "    # If no imputation method selected or only impute each id, for the remaining nan impute direclty with FILL_VALUE\n",
    "    X_resampled = X_resampled.fillna(FILL_VALUE) \n",
    "\n",
    "\n",
    "    # Save preprocessed data\n",
    "    X_resampled.to_csv(f'../data/preprocessed/preprocessed_data_extended_{SAMPLING_INTERVAL}.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normal ds creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3091928/2742523973.py:5: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  X = X.set_index('charttime').groupby('icustay_id').resample(SAMPLING_INTERVAL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging sampled features\n"
     ]
    }
   ],
   "source": [
    "# Resampling\n",
    "if TIME_SAMPLING:\n",
    "    \n",
    "    # Set index and group by 'icustay_id' before resampling\n",
    "    X = X.set_index('charttime').groupby('icustay_id').resample(SAMPLING_INTERVAL)\n",
    "    \n",
    "    # Resample and aggregate features\n",
    "    if MAX_FEATURE_SET:\n",
    "        X_discrete = X[discrete_feat].max().fillna(FILL_VALUE).astype(np.int64)\n",
    "    X_numeric = X[numeric_feat].mean()\n",
    "    X_label = X['aki_stage'].max()\n",
    "\n",
    "    print(\"Merging sampled features\")\n",
    "    try:\n",
    "        X = pd.concat([X_numeric, X_discrete, X_label], axis=1).reset_index()\n",
    "    except:\n",
    "        X = pd.concat([X_numeric, X_label], axis=1).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "# Forward fill again after resampling\n",
    "X['aki_stage'] = X.groupby('icustay_id')['aki_stage'].ffill(limit=RESAMPLE_LIMIT).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "# Ensure binary values (convert any positive number to 1)\n",
    "X['aki_stage'] = (X['aki_stage'] > 0).astype(int)\n",
    "\n",
    "# Shifting labels\n",
    "shift_steps = HOURS_AHEAD // int(SAMPLING_INTERVAL[:-1])\n",
    "X['aki_stage'] = X.groupby('icustay_id')['aki_stage'].shift(-shift_steps)\n",
    "X = X.dropna(subset=['aki_stage'])\n",
    "\n",
    "# Merging not time-dependent data\n",
    "dataset_detail = dataset_detail[dataset_detail['icustay_id'].isin(X['icustay_id'].unique())].sort_values(by=['icustay_id'])\n",
    "try:\n",
    "    # theirs\n",
    "    dataset_detail = pd.get_dummies(dataset_detail, columns=['gender', 'ethnicity_grouped'])\n",
    "except:\n",
    "    #ours\n",
    "    dataset_detail = pd.get_dummies(dataset_detail, columns=['gender'])\n",
    "dataset_detail.drop(['subject_id', 'hadm_id'], axis=1, inplace=True)\n",
    "X = X.merge(dataset_detail, on='icustay_id')\n",
    "X = X.merge(dataset_heightweight, on='icustay_id')\n",
    "X = X.merge(dataset_inr_max, on='icustay_id')\n",
    "\n",
    "# If no imputation method selected or only impute each id, for the remaining nan impute direclty with FILL_VALUE\n",
    "X = X.fillna(FILL_VALUE) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save preprocessed data\n",
    "X.to_csv('../data/preprocessed/preprocessed_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medinf",
   "language": "python",
   "name": "medinf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
