{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for taurus\n",
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir(\"/home/jori152b/DIR/horse/jori152b-medinf/KP_MedInf/model_development\")\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/analysis/data_preprocessed_extended_before_resampling.csv', parse_dates=['charttime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = pd.read_csv('../data/preprocessed/preprocessed_data_extended_6H.csv', parse_dates=['charttime'])\n",
    "x2 = pd.read_csv('../data/preprocessed/preprocessed_data.csv', parse_dates=['charttime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x1.columns)\n",
    "print(x2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the difference in columns between x1 and x2\n",
    "print(x1.columns.difference(x2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = df.describe()\n",
    "print(stats)    \n",
    "# save to csv\n",
    "stats.to_csv('data/analysis/data_preprocessed_extended_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# List of columns to analyze (excluding the datetime and other non-measurement columns)\n",
    "columns_to_analyze = df.columns.difference(['icustay_id', 'charttime', 'hadm_id', 'subject_id'])\n",
    "\n",
    "# Group by icustay_id\n",
    "grouped = df.groupby('icustay_id')\n",
    "\n",
    "# Iterate through each column to analyze\n",
    "for column in columns_to_analyze:\n",
    "    frequencies = []\n",
    "    mean_time_diffs = []\n",
    "    std_time_diffs = []\n",
    "    max_time_diffs = []\n",
    "    min_time_diffs = []\n",
    "\n",
    "    # Iterate through each group (each icustay_id)\n",
    "    for icustay_id, group in grouped:\n",
    "        valid_rows = group[group[column].notna()]\n",
    "\n",
    "        frequency = valid_rows.shape[0]\n",
    "        if frequency > 1:\n",
    "            time_diffs = valid_rows['charttime'].diff().dropna().dt.total_seconds() / 60  # in minutes\n",
    "\n",
    "            mean_time_diff = time_diffs.mean()\n",
    "            std_time_diff = time_diffs.std()\n",
    "            max_time_diff = time_diffs.max()\n",
    "            min_time_diff = time_diffs.min()\n",
    "        else:\n",
    "            mean_time_diff = std_time_diff = max_time_diff = min_time_diff = None\n",
    "\n",
    "        frequencies.append(frequency)\n",
    "        mean_time_diffs.append(mean_time_diff)\n",
    "        std_time_diffs.append(std_time_diff)\n",
    "        max_time_diffs.append(max_time_diff)\n",
    "        min_time_diffs.append(min_time_diff)\n",
    "\n",
    "    # Aggregate the statistics across all icustay_id groups\n",
    "    overall_frequency = sum(frequencies)\n",
    "    overall_mean_time_diff = pd.Series(mean_time_diffs).mean()\n",
    "    overall_std_time_diff = pd.Series(std_time_diffs).mean()\n",
    "    overall_max_time_diff = pd.Series(max_time_diffs).max()\n",
    "    overall_min_time_diff = pd.Series(min_time_diffs).min()\n",
    "\n",
    "    results[column] = {\n",
    "        'frequency': overall_frequency,\n",
    "        'mean_time_diff': overall_mean_time_diff,\n",
    "        'std_time_diff': overall_std_time_diff,\n",
    "        'max_time_diff': overall_max_time_diff,\n",
    "        'min_time_diff': overall_min_time_diff\n",
    "    }\n",
    "\n",
    "# Convert results to a DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)\n",
    "\n",
    "# Optionally, save the results to a CSV file\n",
    "results_df.to_csv('../data/analysis/measurement_statistics_by_icustay.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all the columns in string format\n",
    "X.drop(['first_hosp_stay'], axis=1, inplace = True)\n",
    "X.drop(['first_icu_stay'], axis=1, inplace = True)\n",
    "X.drop(['ethnicity'], axis=1, inplace = True)\n",
    "X.drop(['admittime'], axis=1, inplace = True)\n",
    "X.drop(['dischtime'], axis=1, inplace = True)\n",
    "X.drop(['intime'], axis=1, inplace = True)\n",
    "X.drop(['outtime'], axis=1, inplace = True)\n",
    "X.drop(['dod'], axis=1, inplace = True)\n",
    "X.drop(['charttime'], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations\n",
    "correlations = X.corr()['aki_stage'].drop('aki_stage').sort_values(ascending=False)\n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(20,10))\n",
    "correlations.plot(kind='bar')\n",
    "plt.title('Correlation of all features with the target variable')\n",
    "plt.ylabel('Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the frequency of each attribute, i.e. the distribution of non nan values\n",
    "X.apply(lambda x: x.count(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read np dict\n",
    "results_lstm = np.load('model_development/notebooks/data/results_LSTM.npy', allow_pickle=True).item()   \n",
    "results_xgb = np.load('model_development/notebooks/data/results.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_lstm)\n",
    "print(results_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dataset names and metrics\n",
    "datasets = list(results_lstm.keys())\n",
    "metrics = ['test_accuracy', 'test_roc_auc', 'test_pr_auc']\n",
    "\n",
    "# Set up the plot\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12, 18))\n",
    "fig.suptitle('Comparison of LSTM and XGBoost Models', fontsize=16)\n",
    "\n",
    "# Plot each metric\n",
    "for i, metric in enumerate(metrics):\n",
    "    lstm_values = [results_lstm[dataset][metric] for dataset in datasets]\n",
    "    xgb_values = [results_xgb[dataset][metric] for dataset in datasets]\n",
    "    \n",
    "    x = np.arange(len(datasets))\n",
    "    width = 0.35\n",
    "    \n",
    "    axs[i].bar(x - width/2, lstm_values, width, label='LSTM')\n",
    "    axs[i].bar(x + width/2, xgb_values, width, label='XGBoost')\n",
    "    \n",
    "    axs[i].set_ylabel(metric)\n",
    "    axs[i].set_title(f'{metric.capitalize()} Comparison')\n",
    "    axs[i].set_xticks(x)\n",
    "    axs[i].set_xticklabels(datasets, rotation=45, ha='right')\n",
    "    axs[i].legend()\n",
    "\n",
    "    # Add value labels on top of each bar\n",
    "    for j, v in enumerate(lstm_values):\n",
    "        axs[i].text(j - width/2, v, f'{v:.3f}', ha='center', va='bottom')\n",
    "    for j, v in enumerate(xgb_values):\n",
    "        axs[i].text(j + width/2, v, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_results = np.load('data/optimal_features.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_results = np.load('data/feature_importances.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_selection_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "results = feature_selection_results\n",
    "# Extract data from the results\n",
    "n_features = [result['n_features'] for result in results]\n",
    "val_roc_auc = [result['val_roc_auc'] for result in results]\n",
    "val_pr_auc = [result['val_pr_auc'] for result in results]\n",
    "\n",
    "# Create the plot\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 16))\n",
    "\n",
    "# Plot ROC AUC and PR AUC\n",
    "ax1.plot(n_features, val_roc_auc, 'b-o', label='ROC AUC')\n",
    "ax1.plot(n_features, val_pr_auc, 'r-o', label='PR AUC')\n",
    "ax1.set_xlabel('Number of Features')\n",
    "ax1.set_ylabel('AUC Score')\n",
    "ax1.set_title('ROC AUC and PR AUC vs Number of Features')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Find the best performing model (highest ROC AUC)\n",
    "best_model_index = np.argmax(val_roc_auc)\n",
    "best_model = results[best_model_index]\n",
    "\n",
    "# Get top 15 features from the best model\n",
    "top_features = best_model['sorted_importance']\n",
    "feature_names = [feature[0] for feature in top_features]\n",
    "feature_importance = [feature[1] for feature in top_features]\n",
    "\n",
    "# Plot feature importance for the best model\n",
    "ax2.barh(range(len(feature_names)), feature_importance, align='center')\n",
    "ax2.set_yticks(range(len(feature_names)))\n",
    "ax2.set_yticklabels(feature_names)\n",
    "ax2.invert_yaxis()  # Labels read top-to-bottom\n",
    "ax2.set_xlabel('Feature Importance')\n",
    "ax2.set_title(f'Top Features (Best model with {best_model[\"n_features\"]} features)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medinf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
