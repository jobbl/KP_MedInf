{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"/home/jori152b/DIR/horse/jori152b-medinf/KP_MedInf/model_development/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_results = np.load(os.path.join(data_path, 'models/aki_stage_X_extended_6H.csv_20240915142850/results.npy'), allow_pickle=True)\n",
    "# load as dict\n",
    "xgb_results = np.load(os.path.join(data_path, 'models/aki_stage_X_extended_6H.csv_20240915142850/results.npy'), allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xgb_results['aki_stage_X_extended_6H.csv']['average_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = df.describe()\n",
    "print(stats)    \n",
    "# save to csv\n",
    "stats.to_csv('data/analysis/data_preprocessed_extended_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# List of columns to analyze (excluding the datetime and other non-measurement columns)\n",
    "columns_to_analyze = df.columns.difference(['icustay_id', 'charttime', 'hadm_id', 'subject_id'])\n",
    "\n",
    "# Group by icustay_id\n",
    "grouped = df.groupby('icustay_id')\n",
    "\n",
    "# Iterate through each column to analyze\n",
    "for column in columns_to_analyze:\n",
    "    frequencies = []\n",
    "    mean_time_diffs = []\n",
    "    std_time_diffs = []\n",
    "    max_time_diffs = []\n",
    "    min_time_diffs = []\n",
    "\n",
    "    # Iterate through each group (each icustay_id)\n",
    "    for icustay_id, group in grouped:\n",
    "        valid_rows = group[group[column].notna()]\n",
    "\n",
    "        frequency = valid_rows.shape[0]\n",
    "        if frequency > 1:\n",
    "            time_diffs = valid_rows['charttime'].diff().dropna().dt.total_seconds() / 60  # in minutes\n",
    "\n",
    "            mean_time_diff = time_diffs.mean()\n",
    "            std_time_diff = time_diffs.std()\n",
    "            max_time_diff = time_diffs.max()\n",
    "            min_time_diff = time_diffs.min()\n",
    "        else:\n",
    "            mean_time_diff = std_time_diff = max_time_diff = min_time_diff = None\n",
    "\n",
    "        frequencies.append(frequency)\n",
    "        mean_time_diffs.append(mean_time_diff)\n",
    "        std_time_diffs.append(std_time_diff)\n",
    "        max_time_diffs.append(max_time_diff)\n",
    "        min_time_diffs.append(min_time_diff)\n",
    "\n",
    "    # Aggregate the statistics across all icustay_id groups\n",
    "    overall_frequency = sum(frequencies)\n",
    "    overall_mean_time_diff = pd.Series(mean_time_diffs).mean()\n",
    "    overall_std_time_diff = pd.Series(std_time_diffs).mean()\n",
    "    overall_max_time_diff = pd.Series(max_time_diffs).max()\n",
    "    overall_min_time_diff = pd.Series(min_time_diffs).min()\n",
    "\n",
    "    results[column] = {\n",
    "        'frequency': overall_frequency,\n",
    "        'mean_time_diff': overall_mean_time_diff,\n",
    "        'std_time_diff': overall_std_time_diff,\n",
    "        'max_time_diff': overall_max_time_diff,\n",
    "        'min_time_diff': overall_min_time_diff\n",
    "    }\n",
    "\n",
    "# Convert results to a DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)\n",
    "\n",
    "# Optionally, save the results to a CSV file\n",
    "results_df.to_csv('../data/analysis/measurement_statistics_by_icustay.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all the columns in string format\n",
    "X.drop(['first_hosp_stay'], axis=1, inplace = True)\n",
    "X.drop(['first_icu_stay'], axis=1, inplace = True)\n",
    "X.drop(['ethnicity'], axis=1, inplace = True)\n",
    "X.drop(['admittime'], axis=1, inplace = True)\n",
    "X.drop(['dischtime'], axis=1, inplace = True)\n",
    "X.drop(['intime'], axis=1, inplace = True)\n",
    "X.drop(['outtime'], axis=1, inplace = True)\n",
    "X.drop(['dod'], axis=1, inplace = True)\n",
    "X.drop(['charttime'], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original = pd.read_csv(os.path.join(data_path, 'preprocessed/X_original.csv'), sep=',')\n",
    "X_original.drop(['charttime', 'hadm_id', 'icustay_id'], axis=1, inplace=True)\n",
    "# remove all \"_mean\" from the column names if there is any\n",
    "X_original.columns = X_original.columns.str.replace('_mean', '')\n",
    "print(X_original.columns)\n",
    "\n",
    "X_extended = pd.read_csv(os.path.join(data_path, 'preprocessed/X_extended.csv'), sep=',')\n",
    "X_extended.drop(['charttime', 'hadm_id', 'icustay_id'], axis=1, inplace=True)\n",
    "# remove all \"_mean\" from the column names if there is any\n",
    "X_extended.columns = X_extended.columns.str.replace('_mean', '')\n",
    "print(X_extended.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('difference between original and extended: ', set(X_original.columns) - set(X_extended.columns))\n",
    "print('difference between extended and original: ', set(X_extended.columns) - set(X_original.columns))\n",
    "new_attributes = list(set(X_extended.columns) - set(X_original.columns))\n",
    "print('new attributes: ', new_attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Attributes only in X_original (ethnicity groupings)\n",
    "original_only_attributes = [\n",
    "    'ethnicity_grouped_white', 'ethnicity_grouped_unknown', 'ethnicity_grouped_native',\n",
    "    'ethnicity_grouped_black', 'ethnicity_grouped_hispanic', 'ethnicity_grouped_other',\n",
    "    'ethnicity_grouped_asian'\n",
    "]\n",
    "\n",
    "# Create a copy of X_original with only these attributes and aki_stage\n",
    "X_original_subset = X_original[original_only_attributes + ['aki_stage']].copy()\n",
    "\n",
    "# Rename the columns\n",
    "new_column_names = {\n",
    "    'ethnicity_grouped_white': 'White',\n",
    "    'ethnicity_grouped_unknown': 'Unknown',\n",
    "    'ethnicity_grouped_native': 'Native',\n",
    "    'ethnicity_grouped_black': 'Black',\n",
    "    'ethnicity_grouped_hispanic': 'Hispanic',\n",
    "    'ethnicity_grouped_other': 'Other',\n",
    "    'ethnicity_grouped_asian': 'Asian'\n",
    "}\n",
    "X_original_subset.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "# Calculate correlations\n",
    "correlations = X_original_subset.corr()['aki_stage'].drop('aki_stage').sort_values(ascending=False)\n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(20,10))\n",
    "correlations.plot(kind='bar', color='grey')\n",
    "plt.title('Correlation of Ethnicity with AKI Stage', fontsize=20)\n",
    "plt.ylabel('Correlation', fontsize=16)\n",
    "plt.xlabel('Ethnicity', fontsize=16)\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=45, ha='right', fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=19)\n",
    "\n",
    "# Adjust layout to prevent cutoff of labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add some padding at the bottom for the rotated labels\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_attributes = list(set(X_extended.columns) - set(X_original.columns))\n",
    "\n",
    "print(X_extended.columns)\n",
    "X = X_extended.copy()[new_attributes + ['aki_stage']]\n",
    "# take only the new attributes\n",
    "# # Calculate correlations\n",
    "correlations = X.corr()['aki_stage'].drop('aki_stage').sort_values(ascending=False)\n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(20,10))\n",
    "correlations.plot(kind='bar', color='grey')\n",
    "plt.title('Correlation of all features with the target variable')\n",
    "plt.ylabel('Correlation')\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Adjust layout to prevent cutoff of labels\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to map old names to new names\n",
    "name_mapping = {\n",
    "    'albumin': 'Albumin',\n",
    "    'lactate': 'Lactate',\n",
    "    'bands': 'Immature WBCs',\n",
    "    'height_first': 'Initial Height',\n",
    "    'inr_max': 'Maximum INR',\n",
    "    'platelet': 'Platelet Count',\n",
    "    'bilirubin': 'Bilirubin',\n",
    "    'ptt': 'Partial Thromboplastin Time',\n",
    "    'inr': 'INR',\n",
    "    'weight_first': 'Initial Weight',\n",
    "    'phosphate': 'Phosphate',\n",
    "    'uric_acid': 'Uric Acid',\n",
    "    'pt': 'Prothrombin Time',\n",
    "    'calcium': 'Calcium'\n",
    "}\n",
    "\n",
    "# Create a copy of X_extended\n",
    "X_renamed = X_extended.copy()\n",
    "\n",
    "# Rename the columns\n",
    "X_renamed.rename(columns=name_mapping, inplace=True)\n",
    "\n",
    "# Update the new_attributes list with the renamed columns\n",
    "new_attributes_renamed = [name_mapping.get(attr, attr) for attr in new_attributes]\n",
    "\n",
    "# Use the renamed DataFrame and attribute list for further processing\n",
    "X = X_renamed[new_attributes_renamed + ['aki_stage']]\n",
    "\n",
    "# Calculate correlations\n",
    "correlations = X.corr()['aki_stage'].drop('aki_stage').sort_values(ascending=False)\n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(20,10))\n",
    "correlations.plot(kind='bar', color='grey')\n",
    "plt.title('Correlation of New Features with AKI Stage')\n",
    "plt.ylabel('Correlation')\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=45, ha='right', fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=19)\n",
    "\n",
    "# Adjust layout to prevent cutoff of labels\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# Read the data\n",
    "data = io.StringIO('''Wall time,Step,Value\n",
    "1726512293.467726,1,0.7178572416305542\n",
    "1726512303.369601,2,0.6912493109703064\n",
    "1726512312.8535783,3,0.7513433694839478\n",
    "1726512322.4488628,4,0.7845879793167114\n",
    "1726512332.2577426,5,0.7722629904747009\n",
    "1726512341.7285247,6,0.7896556258201599\n",
    "1726512352.015021,7,0.7530167698860168\n",
    "1726512361.736987,8,0.7810222506523132\n",
    "1726512371.3558726,9,0.7355340719223022\n",
    "1726512381.518271,10,0.7800203561782837\n",
    "1726512391.6949794,11,0.8160804510116577\n",
    "1726512401.555636,12,0.7953928112983704\n",
    "1726512411.5994918,13,0.7935769557952881\n",
    "1726512421.809925,14,0.8084826469421387\n",
    "1726512431.9026322,15,0.8044590353965759\n",
    "1726512441.8436167,16,0.8052487373352051\n",
    "1726512452.1929953,17,0.7796595692634583\n",
    "1726512462.5377321,18,0.7876774668693542\n",
    "1726512473.255793,19,0.7989493608474731\n",
    "1726512483.9579756,20,0.7957519888877869\n",
    "1726512494.2151084,21,0.8039131760597229''')\n",
    "\n",
    "df = pd.read_csv(data)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['Step'], df['Value'], color='gray', marker='o')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('ROC-AUC Score over Epochs', fontsize=16, color='black')\n",
    "plt.xlabel('Epoch', fontsize=12, color='black')\n",
    "plt.ylabel('ROC-AUC Score', fontsize=12, color='black')\n",
    "plt.grid(True, linestyle='--', alpha=0.7, color='lightgray')\n",
    "\n",
    "# Set y-axis limits to start from 0.5 for better visualization of ROC-AUC scores\n",
    "plt.ylim(0.5, 1.0)\n",
    "\n",
    "# Use a grayscale color map for the background\n",
    "plt.gca().set_facecolor('#f0f0f0')\n",
    "\n",
    "# Customize tick colors\n",
    "plt.tick_params(colors='black')\n",
    "\n",
    "# Add annotations for the highest and lowest scores\n",
    "max_score = df['Value'].max()\n",
    "min_score = df['Value'].min()\n",
    "max_epoch = df.loc[df['Value'].idxmax(), 'Step']\n",
    "min_epoch = df.loc[df['Value'].idxmin(), 'Step']\n",
    "\n",
    "plt.annotate(f'Max: {max_score:.4f}', xy=(max_epoch, max_score), xytext=(5, 5), \n",
    "             textcoords='offset points', ha='left', va='bottom',\n",
    "             bbox=dict(boxstyle='round,pad=0.5', fc='white', ec='gray', alpha=0.7),\n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "plt.annotate(f'Min: {min_score:.4f}', xy=(min_epoch, min_score), xytext=(5, -5), \n",
    "             textcoords='offset points', ha='left', va='top',\n",
    "             bbox=dict(boxstyle='round,pad=0.5', fc='white', ec='gray', alpha=0.7),\n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_results = np.load(\"/home/jori152b/DIR/horse/jori152b-medinf/KP_MedInf/model_development/data/models/xgb_cross_validation_results.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract time points and scores\n",
    "time_points = ['1H', '2H', '4H', '6H', '8H', '12H', '24H']\n",
    "brier_scores_original = []\n",
    "brier_scores_extended = []\n",
    "roc_auc_scores_original = []\n",
    "roc_auc_scores_extended = []\n",
    "accuracy_scores_original = []\n",
    "accuracy_scores_extended = []\n",
    "\n",
    "for time_point in time_points:\n",
    "    original_key = f'aki_stage_X_original_{time_point}.csv'\n",
    "    extended_key = f'aki_stage_X_extended_{time_point}.csv'\n",
    "    \n",
    "    brier_scores_original.append(xgb_results[original_key]['average_scores']['val_brier'])\n",
    "    brier_scores_extended.append(xgb_results[extended_key]['average_scores']['val_brier'])\n",
    "    roc_auc_scores_original.append(xgb_results[original_key]['average_scores']['val_roc_auc'])\n",
    "    roc_auc_scores_extended.append(xgb_results[extended_key]['average_scores']['val_roc_auc'])\n",
    "    accuracy_scores_original.append(xgb_results[original_key]['average_scores']['val_accuracy'])\n",
    "    accuracy_scores_extended.append(xgb_results[extended_key]['average_scores']['val_accuracy'])\n",
    "    \n",
    "\n",
    "# Create the plot\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
    "plt.style.use('grayscale')\n",
    "\n",
    "# Brier Score plot\n",
    "ax1.plot(time_points, brier_scores_original, marker='o', linestyle='-', color='black', label='Original')\n",
    "ax1.plot(time_points, brier_scores_extended, marker='s', linestyle='--', color='gray', label='Extended')\n",
    "ax1.set_ylabel('Brier Score')\n",
    "ax1.set_title('Average Brier Scores')\n",
    "ax1.legend()\n",
    "ax1.grid(True, linestyle=':', alpha=0.7)\n",
    "\n",
    "# ROC-AUC plot\n",
    "ax2.plot(time_points, roc_auc_scores_original, marker='o', linestyle='-', color='black', label='Original')\n",
    "ax2.plot(time_points, roc_auc_scores_extended, marker='s', linestyle='--', color='gray', label='Extended')\n",
    "ax2.set_xlabel('Time Points')\n",
    "ax2.set_ylabel('ROC-AUC Score')\n",
    "ax2.set_title('Average ROC-AUC Scores')\n",
    "ax2.legend()\n",
    "ax2.grid(True, linestyle=':', alpha=0.7)\n",
    "\n",
    "ax3.plot(time_points, accuracy_scores_original, marker='o', linestyle='-', color='black', label='Original')\n",
    "ax3.plot(time_points, accuracy_scores_extended, marker='s', linestyle='--', color='gray', label='Extended')\n",
    "ax3.set_xlabel('Time Points')\n",
    "ax3.set_ylabel('Accuracy Score')\n",
    "ax3.set_title('Average Accuracy Scores')\n",
    "ax3.legend()\n",
    "ax3.grid(True, linestyle=':', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(os.path.join(data_path, 'preprocessed/X_original.csv'), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the frequency of each attribute, i.e. the distribution of non nan values\n",
    "X.apply(lambda x: x.count(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read np dict\n",
    "results_lstm = np.load('model_development/notebooks/data/results_LSTM.npy', allow_pickle=True).item()   \n",
    "results_xgb = np.load('model_development/notebooks/data/results.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_lstm)\n",
    "print(results_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dataset names and metrics\n",
    "datasets = list(results_lstm.keys())\n",
    "metrics = ['test_accuracy', 'test_roc_auc', 'test_pr_auc']\n",
    "\n",
    "# Set up the plot\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12, 18))\n",
    "fig.suptitle('Comparison of LSTM and XGBoost Models', fontsize=16)\n",
    "\n",
    "# Plot each metric\n",
    "for i, metric in enumerate(metrics):\n",
    "    lstm_values = [results_lstm[dataset][metric] for dataset in datasets]\n",
    "    xgb_values = [results_xgb[dataset][metric] for dataset in datasets]\n",
    "    \n",
    "    x = np.arange(len(datasets))\n",
    "    width = 0.35\n",
    "    \n",
    "    axs[i].bar(x - width/2, lstm_values, width, label='LSTM')\n",
    "    axs[i].bar(x + width/2, xgb_values, width, label='XGBoost')\n",
    "    \n",
    "    axs[i].set_ylabel(metric)\n",
    "    axs[i].set_title(f'{metric.capitalize()} Comparison')\n",
    "    axs[i].set_xticks(x)\n",
    "    axs[i].set_xticklabels(datasets, rotation=45, ha='right')\n",
    "    axs[i].legend()\n",
    "\n",
    "    # Add value labels on top of each bar\n",
    "    for j, v in enumerate(lstm_values):\n",
    "        axs[i].text(j - width/2, v, f'{v:.3f}', ha='center', va='bottom')\n",
    "    for j, v in enumerate(xgb_values):\n",
    "        axs[i].text(j + width/2, v, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_results = np.load('data/optimal_features.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_results = np.load('data/feature_importances.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_selection_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "results = feature_selection_results\n",
    "# Extract data from the results\n",
    "n_features = [result['n_features'] for result in results]\n",
    "val_roc_auc = [result['val_roc_auc'] for result in results]\n",
    "val_pr_auc = [result['val_pr_auc'] for result in results]\n",
    "\n",
    "# Create the plot\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 16))\n",
    "\n",
    "# Plot ROC AUC and PR AUC\n",
    "ax1.plot(n_features, val_roc_auc, 'b-o', label='ROC AUC')\n",
    "ax1.plot(n_features, val_pr_auc, 'r-o', label='PR AUC')\n",
    "ax1.set_xlabel('Number of Features')\n",
    "ax1.set_ylabel('AUC Score')\n",
    "ax1.set_title('ROC AUC and PR AUC vs Number of Features')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Find the best performing model (highest ROC AUC)\n",
    "best_model_index = np.argmax(val_roc_auc)\n",
    "best_model = results[best_model_index]\n",
    "\n",
    "# Get top 15 features from the best model\n",
    "top_features = best_model['sorted_importance']\n",
    "feature_names = [feature[0] for feature in top_features]\n",
    "feature_importance = [feature[1] for feature in top_features]\n",
    "\n",
    "# Plot feature importance for the best model\n",
    "ax2.barh(range(len(feature_names)), feature_importance, align='center')\n",
    "ax2.set_yticks(range(len(feature_names)))\n",
    "ax2.set_yticklabels(feature_names)\n",
    "ax2.invert_yaxis()  # Labels read top-to-bottom\n",
    "ax2.set_xlabel('Feature Importance')\n",
    "ax2.set_title(f'Top Features (Best model with {best_model[\"n_features\"]} features)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medinf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
